{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2770a8-9f53-45dd-90b6-5eb0e0a93cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Texto0.pdf', 'Texto1.pdf', 'Texto2.pdf', 'Texto3.pdf', 'Texto4.pdf'])\n",
      "['Texto0.pdf', 'Texto1.pdf', 'Texto2.pdf', 'Texto3.pdf', 'Texto4.pdf']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Ruta del archivo JSON\n",
    "ruta_archivo = \"F:/nuevo_conocimiento/Alex Project/New_part_project/diccionario_textos.json\"\n",
    "\n",
    "# Abrir el archivo y cargar su contenido como un diccionario\n",
    "with open(ruta_archivo, 'r', encoding='utf-8') as f:\n",
    "    contenido_json = json.load(f)\n",
    "\n",
    "# Ahora, puedes trabajar con el contenido del archivo JSON, que está almacenado en la variable `contenido_json`\n",
    "# Por ejemplo, puedes imprimirlo\n",
    "print(contenido_json.keys())\n",
    "archivos = list(contenido_json.keys())\n",
    "print(archivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c192f4c3-d9b7-4020-9d1e-4bfda70a3cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_secciones(inicio,fin,archivo):\n",
    "    #print(llaves_lista)\n",
    "    #print(contenido_json[archivo])\n",
    "    # Títulos de inicio y fin que deseas seleccionar\n",
    "    titulo_inicio = inicio\n",
    "    titulo_fin = fin\n",
    "    contenido = \"\"\n",
    "    # Seleccionar el texto entre los títulos de inicio y fin\n",
    "    texto_seleccionado = {}\n",
    "    seleccionando = False\n",
    "    for titulo, contenido in contenido_json[archivo].items():\n",
    "        if titulo == titulo_inicio:\n",
    "            seleccionando = True\n",
    "        elif titulo == titulo_fin:\n",
    "            seleccionando = False\n",
    "            break\n",
    "        if seleccionando:\n",
    "            #nuevo_contenido = nuevo_contenido + \"\" contenido\n",
    "            texto_seleccionado[titulo] = contenido\n",
    "    \n",
    "    # Imprimir el texto seleccionado\n",
    "    #for titulo, contenido in texto_seleccionado.items():\n",
    "    #    print(f\"Título: {titulo}\")\n",
    "    #    print(f\"Contenido: {contenido}\") \n",
    "    #print(\"************************************************\")\n",
    "    #print(texto_seleccionado)\n",
    "    return texto_seleccionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d890761f-a7e9-4dac-9d08-cb1a96c0987c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['DistilBERT: A Novel Approach to Detect Text Generated by Large Language Models (LLM)', 'Abstract', '1 Introduction', 'Concerns with LLM generated text', '2 Experimental Setup', 'Datasets', 'Software Setup', 'Data Preprocessing', '3 Methodology', 'Models', 'Metrics of Evaluation', '4 Results and Discussion', 'Confusion Matrix', '4.1.1 Test Set Confusion Matrix', '4.1.2 Validation Set Confusion Matrix', 'Classification Report', '4.2.1 Test Set Classification Report', '4.2.2 Validation Set Classification Report', 'Model Performance Analysis', '4.3.1 Confusion Matrix Analysis', '4.3.2 Classification Report Analysis', 'Implications', 'Limitations', '5 Conclusion', 'Future Work', 'Data Availability Statement', 'References'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' (LLM)\\n\\nBV Pranay Kumar (pranaybv4u@gmail.com )\\n\\nKakatiya University\\n\\nMD Shaheer Ahmed\\n\\nChristu Jyothi Institute of Technology and Science\\n\\nManchala Sadanandam\\n\\nKakatiya University\\n\\n###### Abstract\\n\\nWe propose a novel approach to detect text generated by large language models.\\n\\n\\n\\n# DistilBERT: A Novel Approach to Detect Text Generated by Large Language Models (LLM)\\n\\nBV Pranay Kumar\\\\({}^{1,2}\\\\)\\n\\n\\\\({}^{1}\\\\)Department of Computer Science and Engineering, Kakatiya University, Warangal, 506009, Telangana, India.\\n\\n MD Shaheer Ahmed\\\\({}^{2,3}\\\\)\\n\\n\\\\({}^{1}\\\\)Department of Computer Science and Engineering, Christu Jyothi Institute of Technology and Science, Jangaon, 506167, Telangana, India.\\n\\n Manchala Sadanandam\\\\({}^{1,2}\\\\)\\n\\n\\\\({}^{1}\\\\)Department of Computer Science and Engineering, Kakatiya University, Warangal, 506009, Telangana, India.\\n\\n\\\\({}^{2}\\\\)Department of Computer Science and Engineering, Christu Jyothi Institute of Technology and Science, Jangaon, 506167, Telangana, India.\\n\\n\\\\({}^{3}\\\\)Department of Computer Science and Engineering, Kakatiya University, Warangal, 506009, Telangana, India.\\n\\n\\\\({}^{4}\\\\)Corresponding author(s). E-mail(s): pranaybv4u@gmail.com;\\n\\nContributing authors: shaheerhasidea@gmail.com; sadanb4u@gmail.com;\\n\\n\\\\({}^{\\\\dagger}\\\\)These authors contributed equally to this work.\\n\\n###### Abstract\\n\\nLarge language models (LLMs) have emerged as powerful tools for generating human-quality text, raising concerns about their potential for misuse in academic settings. This paper investigates the use of DistilBERT, a distilled version of BERT, for detecting LLM-generated text. We evaluate its performance on two publicly available datasets, LLM-Detect AI Generated Text and DAIGT-V3 Train Dataset, achieving an average accuracy of around 94%. Our findings suggest that DistilBERT is a promising tool for safeguarding academic integrity in the era of LLMs.\\n\\n**Keywords:** DistilBert, BERT, LLM, Transformer, LLM-generated text, ChatGPT\\n\\n## 1 Introduction\\n\\nThe rapid evolution of Large Language Models (LLMs)[1] presents both remarkable opportunities and significant challenges for academic settings, including higher education and research. With their fluency and factuality, LLMs hold promise for tasks like generating content, summarizing research, and automating administrative processes[2]. However, their ability to mimic human writing raises concerns about potential misuse in fields like scientific authorship, where authenticity and integrity are paramount. For educators, distinguishing student-generated text from LLM outputs becomes crucial in ensuring the validity of assignments and assessments.\\n\\nAddressing these concerns lies in developing reliable methods for detecting LLM-generated text. Among the popular LLMs, the Bidirectional Encoder Representations from Transformers (BERT) [3] model stands out for its high performance in various natural language processing tasks. However, its immense size and computational complexity limit its widespread adoptionin real-time applications. This is where DistilBERT [4] emerges as a compelling alternative. A smaller, faster, and more resource-efficient version of BERT, DistilBERT inherits its predecessor\\'s capabilities while offering broader accessibility and lower deployment costs [5].\\n\\nThis research investigates the potential of DistilBERT in tackling the crucial task of LLM generated text detection. We delve into evaluating its performance against human-written and LLM-generated text, focusing on its ability to accurately discern the origin of a given text sample. The findings aim to shed light on DistilBERT\\'s suitability as a practical solution for safeguarding academic integrity and empowering educators in a landscape increasingly influenced by advanced language models.\\n\\n### Concerns with LLM generated text\\n\\nWhile LLMs like ChatGPT [6], Bard [7], and Claude [8] offer mesmerizing capabilities, their very strengths pose inherent dangers, particularly in academic settings. These models excel at generating text that is not only grammatically correct and stylistically cohesive but also often infused with factual details gleaned from vast datasets. This ability to \"hallucinate [9]\" knowledge, weave intricate narratives, and even engage in self-referential loops, aptly dubbed the \"Curse of Recursion[10],\" presents a two-fold threat:\\n\\n**1. Deception and Plagiarism [11]**: The ease with which LLMs can mimic human writing opens the door to a wave of academic dishonesty. Imagine an essay composed entirely by an LLM, seamlessly integrated with citations and seemingly backed by factual evidence. Unwary educators and plagiarism detection systems might struggle to identify such fabrications, potentially undermining the entire foundation of academic trust and intellectual merit.\\n\\n**2. Erosion of Critical Thinking [12]**: The abundance of readily available, machine-generated \"knowledge\" risks fostering a culture of intellectual dependence. Students accustomed to relying on LLMs for summaries, research assistance, and even essay writing might lose the crucial skills of critical evaluation, independent thought, and original argumentation. This could lead to a generation ill-equipped to navigate the complexities of information overload and discern truth from fiction.\\n\\nTherefore, developing robust methods for detecting LLM-generated text is not just a technological challenge but an ethical imperative. It is about safeguarding the very essence of academic endeavor - the pursuit of genuine understanding, honest inquiry, and the independent construction of knowledge. DistilBERT, with its potential for efficient and accurate LLM detection, emerges as a promising tool in this crucial fight. By empowering educators and upholding academic integrity, we can ensure that the transformative power of language models is harnessed for good, fostering a future where technology augments human intellect rather than supplants it.\\n\\n## 2 Experimental Setup\\n\\n### Datasets\\n\\nTwo datasets were utilized in this research: the \"LLM - Detect AI Generated Text\" dataset and the \"DAIGT-V3 Train Dataset\".\\n\\nThe \"LLM - Detect AI Generated Text\" dataset, available on Kaggle, comprises a collection of essays, some authored by students and others generated by various large language models (LLMs). The objective of the dataset is to identify whether a particular essay was produced by an LLM. It includes around 10,000 essays, all penned in response to one of seven essay prompts. The essays from two prompts form the training set, while the rest make up the hidden test set. Almost all training set essays were written by students, with only a few LLM-generated essays provided as examples.\\n\\nThe \"LLM - Detect AI Generated Text\" dataset includes three CSV files:\\n\\n* **train_prompts.csv**: Contains prompts used to generate the essays in the training set.\\n* **train_essays.csv**: Contains 1378 unique values and four columns (\\'id\\', \\'prompt_id\\', \\'text\\', \\'generated\\'). The \\'generated\\' column indicates whether the text was generated by an LLM.\\n* **test_essays.csv**: Contains three columns (\\'id\\', \\'prompt_id\\', \\'text\\').\\n\\nOn the other hand, the \"DAIGT-V3 Train Dataset\", accessible on Kaggle, is designed to train and evaluate models for detecting LLM-generated text. This dataset includes 20,000 human-written essays and 20,000 LLM-generated essays. Like the \"LLM - Detect AI Generated Text\" dataset, the essays in this dataset are written in response to a variety of prompts, which are also provided in the dataset. The dataset includes two CSV files:\\n\\n* **test_v3_drcat_01.csv**: Contains five columns (\\'text\\', \\'label\\', \\'prompt_name\\', \\'source\\', \\'RDizzl3_seven\\').\\n* **train_v3_drcat_02.csv**: Contains six columns (\\'text\\', \\'label\\', \\'prompt_name\\', \\'source\\', \\'RDizzl3_seven\\', \\'model\\').\\n\\nBoth datasets provide valuable data for training and evaluating models capable of distinguishing between human-written and AI-generated text.\\n\\n### Software Setup\\n\\nThe proposed methods of this study were implemented using Python programming language. The proposed method was implemented using Hugging face transformers class embedded in Python. The libraries used and their respective versions are TensorFlow version 2.12.0, Keras version 0.1.7, KerasNLP version 0.6.1, NumPy version 1.23.5, Pandas version 2.0.3, scikit-learn version 1.1.3, matplotlib version 3.7.3, and seaborn version 0.14.1.\\n\\n### Data Preprocessing\\n\\nData preprocessing is a vital stage in any machine learning endeavor, particularly when dealing with text data. It involves cleaning the data and preparing it for the model. In the realm of Natural Language Processing (NLP)[13], text data can contain noise in various forms such as emotions, punctuation, and text in different cases.\\n\\nFor the \"LLM - Detect AI Generated Text\" and \"DAIGT-V3 Train Dataset\", several preprocessing steps were undertaken. Initially, all the text was converted to lowercase to ensure uniformity and prevent duplication due to case differences. Subsequently, punctuation marks and numbers were removed from the text as they often do not contribute meaningful information for the task at hand.\\n\\nNext, common words, known as stopwords, that do not carry much meaning were eliminated. These often include words like \\'is\\', \\'the\\', \\'and\\', etc. Following this, techniques known as stemming and lemmatization were used to reduce words to their root form. For instance, \\'running\\' might be reduced to \\'run\\'. This step aids in grouping similar words together. Lastly, extra white spaces in the text were removed to clean up the text.\\n\\nBy applying these preprocessing steps, the text data was made more suitable for the subsequent machine learning model, thereby enhancing the model\\'s ability to extract useful features from the text and improve its predictive performance\\n\\n## 3 Methodology\\n\\n### Models\\n\\nThe primary model used in this research is DistilBERT, specifically the **distil_bert_base_uncased** variant. DistilBERT is a distilled version of BERT (Bidirectional Encoder Representations from Transformers), a transformer-based machine learning technique for natural language processing tasks.\\n\\nBERT is a powerful language model that has significantly improved the state-of-the-art on many Natural Language Processing tasks. However, it is also quite large, with models containing billions of parameters [14] and being trained on massive datasets. As a result, using BERT for production applications can be challenging due to the high computational requirements for training and inference.\\n\\nFigure 1: Architecture of DistilBERT\\n\\nThe architecture of DistilBERT is shown in Figure 1. DistilBERT addresses these issues by creating a smaller, faster, and cheaper version of BERT. It achieves this by using a process known as distillation, where a larger model (the teacher) transfers its knowledge to a smaller model (the student). The student model is trained to mimic the output of the teacher model, thus retaining most of its performance while reducing its size and computational requirements.\\n\\nThe **distil_bert_base_uncased** variant of DistilBERT is pre-trained on the same corpus as the BERT base model in a self-supervised manner. This means it was trained on raw texts without any human labeling, using an automatic process to generate inputs and labels from those texts using the BERT base model. It was trained with three objectives: distillation loss, masked language modeling (MLM) [15], and cosine embedding loss.\\n\\nCompared to BERT, DistilBERT retains more than 95% of the performance of BERT while having 40% fewer parameters. In terms of inference time, DistilBERT is more than 60% faster and requires 40% less memory than BERT. These advantages make DistilBERT a highly effective choice for many NLP tasks, especially in scenarios where computational resources are limited.\\n\\nThe Figure 2 depicts the DistilBERT classification process for identifying whether a given text was written by a human or generated by a machine. First, the input text is divided into individual tokens (words or sub-words) and then converted into numerical representations called embeddings. These embeddings are then fed into multiple attention layers that analyze the relationships between the tokens. Finally, a classification layer determines the final outcome, classifying the text as either human-written or machine-generated.\\n\\n### '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(contenido_json['Texto2.pdf'].keys())\n",
    "\n",
    "contenido_json['Texto2.pdf']['Models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e52fc7f3-cd44-42a4-9632-395ade100343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'3 Methodology': '', 'Models': ' (LLM)\\n\\nBV Pranay Kumar (pranaybv4u@gmail.com )\\n\\nKakatiya University\\n\\nMD Shaheer Ahmed\\n\\nChristu Jyothi Institute of Technology and Science\\n\\nManchala Sadanandam\\n\\nKakatiya University\\n\\n###### Abstract\\n\\nWe propose a novel approach to detect text generated by large language models.\\n\\n\\n\\n# DistilBERT: A Novel Approach to Detect Text Generated by Large Language Models (LLM)\\n\\nBV Pranay Kumar\\\\({}^{1,2}\\\\)\\n\\n\\\\({}^{1}\\\\)Department of Computer Science and Engineering, Kakatiya University, Warangal, 506009, Telangana, India.\\n\\n MD Shaheer Ahmed\\\\({}^{2,3}\\\\)\\n\\n\\\\({}^{1}\\\\)Department of Computer Science and Engineering, Christu Jyothi Institute of Technology and Science, Jangaon, 506167, Telangana, India.\\n\\n Manchala Sadanandam\\\\({}^{1,2}\\\\)\\n\\n\\\\({}^{1}\\\\)Department of Computer Science and Engineering, Kakatiya University, Warangal, 506009, Telangana, India.\\n\\n\\\\({}^{2}\\\\)Department of Computer Science and Engineering, Christu Jyothi Institute of Technology and Science, Jangaon, 506167, Telangana, India.\\n\\n\\\\({}^{3}\\\\)Department of Computer Science and Engineering, Kakatiya University, Warangal, 506009, Telangana, India.\\n\\n\\\\({}^{4}\\\\)Corresponding author(s). E-mail(s): pranaybv4u@gmail.com;\\n\\nContributing authors: shaheerhasidea@gmail.com; sadanb4u@gmail.com;\\n\\n\\\\({}^{\\\\dagger}\\\\)These authors contributed equally to this work.\\n\\n###### Abstract\\n\\nLarge language models (LLMs) have emerged as powerful tools for generating human-quality text, raising concerns about their potential for misuse in academic settings. This paper investigates the use of DistilBERT, a distilled version of BERT, for detecting LLM-generated text. We evaluate its performance on two publicly available datasets, LLM-Detect AI Generated Text and DAIGT-V3 Train Dataset, achieving an average accuracy of around 94%. Our findings suggest that DistilBERT is a promising tool for safeguarding academic integrity in the era of LLMs.\\n\\n**Keywords:** DistilBert, BERT, LLM, Transformer, LLM-generated text, ChatGPT\\n\\n## 1 Introduction\\n\\nThe rapid evolution of Large Language Models (LLMs)[1] presents both remarkable opportunities and significant challenges for academic settings, including higher education and research. With their fluency and factuality, LLMs hold promise for tasks like generating content, summarizing research, and automating administrative processes[2]. However, their ability to mimic human writing raises concerns about potential misuse in fields like scientific authorship, where authenticity and integrity are paramount. For educators, distinguishing student-generated text from LLM outputs becomes crucial in ensuring the validity of assignments and assessments.\\n\\nAddressing these concerns lies in developing reliable methods for detecting LLM-generated text. Among the popular LLMs, the Bidirectional Encoder Representations from Transformers (BERT) [3] model stands out for its high performance in various natural language processing tasks. However, its immense size and computational complexity limit its widespread adoptionin real-time applications. This is where DistilBERT [4] emerges as a compelling alternative. A smaller, faster, and more resource-efficient version of BERT, DistilBERT inherits its predecessor\\'s capabilities while offering broader accessibility and lower deployment costs [5].\\n\\nThis research investigates the potential of DistilBERT in tackling the crucial task of LLM generated text detection. We delve into evaluating its performance against human-written and LLM-generated text, focusing on its ability to accurately discern the origin of a given text sample. The findings aim to shed light on DistilBERT\\'s suitability as a practical solution for safeguarding academic integrity and empowering educators in a landscape increasingly influenced by advanced language models.\\n\\n### Concerns with LLM generated text\\n\\nWhile LLMs like ChatGPT [6], Bard [7], and Claude [8] offer mesmerizing capabilities, their very strengths pose inherent dangers, particularly in academic settings. These models excel at generating text that is not only grammatically correct and stylistically cohesive but also often infused with factual details gleaned from vast datasets. This ability to \"hallucinate [9]\" knowledge, weave intricate narratives, and even engage in self-referential loops, aptly dubbed the \"Curse of Recursion[10],\" presents a two-fold threat:\\n\\n**1. Deception and Plagiarism [11]**: The ease with which LLMs can mimic human writing opens the door to a wave of academic dishonesty. Imagine an essay composed entirely by an LLM, seamlessly integrated with citations and seemingly backed by factual evidence. Unwary educators and plagiarism detection systems might struggle to identify such fabrications, potentially undermining the entire foundation of academic trust and intellectual merit.\\n\\n**2. Erosion of Critical Thinking [12]**: The abundance of readily available, machine-generated \"knowledge\" risks fostering a culture of intellectual dependence. Students accustomed to relying on LLMs for summaries, research assistance, and even essay writing might lose the crucial skills of critical evaluation, independent thought, and original argumentation. This could lead to a generation ill-equipped to navigate the complexities of information overload and discern truth from fiction.\\n\\nTherefore, developing robust methods for detecting LLM-generated text is not just a technological challenge but an ethical imperative. It is about safeguarding the very essence of academic endeavor - the pursuit of genuine understanding, honest inquiry, and the independent construction of knowledge. DistilBERT, with its potential for efficient and accurate LLM detection, emerges as a promising tool in this crucial fight. By empowering educators and upholding academic integrity, we can ensure that the transformative power of language models is harnessed for good, fostering a future where technology augments human intellect rather than supplants it.\\n\\n## 2 Experimental Setup\\n\\n### Datasets\\n\\nTwo datasets were utilized in this research: the \"LLM - Detect AI Generated Text\" dataset and the \"DAIGT-V3 Train Dataset\".\\n\\nThe \"LLM - Detect AI Generated Text\" dataset, available on Kaggle, comprises a collection of essays, some authored by students and others generated by various large language models (LLMs). The objective of the dataset is to identify whether a particular essay was produced by an LLM. It includes around 10,000 essays, all penned in response to one of seven essay prompts. The essays from two prompts form the training set, while the rest make up the hidden test set. Almost all training set essays were written by students, with only a few LLM-generated essays provided as examples.\\n\\nThe \"LLM - Detect AI Generated Text\" dataset includes three CSV files:\\n\\n* **train_prompts.csv**: Contains prompts used to generate the essays in the training set.\\n* **train_essays.csv**: Contains 1378 unique values and four columns (\\'id\\', \\'prompt_id\\', \\'text\\', \\'generated\\'). The \\'generated\\' column indicates whether the text was generated by an LLM.\\n* **test_essays.csv**: Contains three columns (\\'id\\', \\'prompt_id\\', \\'text\\').\\n\\nOn the other hand, the \"DAIGT-V3 Train Dataset\", accessible on Kaggle, is designed to train and evaluate models for detecting LLM-generated text. This dataset includes 20,000 human-written essays and 20,000 LLM-generated essays. Like the \"LLM - Detect AI Generated Text\" dataset, the essays in this dataset are written in response to a variety of prompts, which are also provided in the dataset. The dataset includes two CSV files:\\n\\n* **test_v3_drcat_01.csv**: Contains five columns (\\'text\\', \\'label\\', \\'prompt_name\\', \\'source\\', \\'RDizzl3_seven\\').\\n* **train_v3_drcat_02.csv**: Contains six columns (\\'text\\', \\'label\\', \\'prompt_name\\', \\'source\\', \\'RDizzl3_seven\\', \\'model\\').\\n\\nBoth datasets provide valuable data for training and evaluating models capable of distinguishing between human-written and AI-generated text.\\n\\n### Software Setup\\n\\nThe proposed methods of this study were implemented using Python programming language. The proposed method was implemented using Hugging face transformers class embedded in Python. The libraries used and their respective versions are TensorFlow version 2.12.0, Keras version 0.1.7, KerasNLP version 0.6.1, NumPy version 1.23.5, Pandas version 2.0.3, scikit-learn version 1.1.3, matplotlib version 3.7.3, and seaborn version 0.14.1.\\n\\n### Data Preprocessing\\n\\nData preprocessing is a vital stage in any machine learning endeavor, particularly when dealing with text data. It involves cleaning the data and preparing it for the model. In the realm of Natural Language Processing (NLP)[13], text data can contain noise in various forms such as emotions, punctuation, and text in different cases.\\n\\nFor the \"LLM - Detect AI Generated Text\" and \"DAIGT-V3 Train Dataset\", several preprocessing steps were undertaken. Initially, all the text was converted to lowercase to ensure uniformity and prevent duplication due to case differences. Subsequently, punctuation marks and numbers were removed from the text as they often do not contribute meaningful information for the task at hand.\\n\\nNext, common words, known as stopwords, that do not carry much meaning were eliminated. These often include words like \\'is\\', \\'the\\', \\'and\\', etc. Following this, techniques known as stemming and lemmatization were used to reduce words to their root form. For instance, \\'running\\' might be reduced to \\'run\\'. This step aids in grouping similar words together. Lastly, extra white spaces in the text were removed to clean up the text.\\n\\nBy applying these preprocessing steps, the text data was made more suitable for the subsequent machine learning model, thereby enhancing the model\\'s ability to extract useful features from the text and improve its predictive performance\\n\\n## 3 Methodology\\n\\n### Models\\n\\nThe primary model used in this research is DistilBERT, specifically the **distil_bert_base_uncased** variant. DistilBERT is a distilled version of BERT (Bidirectional Encoder Representations from Transformers), a transformer-based machine learning technique for natural language processing tasks.\\n\\nBERT is a powerful language model that has significantly improved the state-of-the-art on many Natural Language Processing tasks. However, it is also quite large, with models containing billions of parameters [14] and being trained on massive datasets. As a result, using BERT for production applications can be challenging due to the high computational requirements for training and inference.\\n\\nFigure 1: Architecture of DistilBERT\\n\\nThe architecture of DistilBERT is shown in Figure 1. DistilBERT addresses these issues by creating a smaller, faster, and cheaper version of BERT. It achieves this by using a process known as distillation, where a larger model (the teacher) transfers its knowledge to a smaller model (the student). The student model is trained to mimic the output of the teacher model, thus retaining most of its performance while reducing its size and computational requirements.\\n\\nThe **distil_bert_base_uncased** variant of DistilBERT is pre-trained on the same corpus as the BERT base model in a self-supervised manner. This means it was trained on raw texts without any human labeling, using an automatic process to generate inputs and labels from those texts using the BERT base model. It was trained with three objectives: distillation loss, masked language modeling (MLM) [15], and cosine embedding loss.\\n\\nCompared to BERT, DistilBERT retains more than 95% of the performance of BERT while having 40% fewer parameters. In terms of inference time, DistilBERT is more than 60% faster and requires 40% less memory than BERT. These advantages make DistilBERT a highly effective choice for many NLP tasks, especially in scenarios where computational resources are limited.\\n\\nThe Figure 2 depicts the DistilBERT classification process for identifying whether a given text was written by a human or generated by a machine. First, the input text is divided into individual tokens (words or sub-words) and then converted into numerical representations called embeddings. These embeddings are then fed into multiple attention layers that analyze the relationships between the tokens. Finally, a classification layer determines the final outcome, classifying the text as either human-written or machine-generated.\\n\\n### ', 'Metrics of Evaluation': \"\\n\\nThe performance of the models was evaluated using four key metrics: accuracy, precision, recall, and the F1 score. These metrics were calculated based on the True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN) values derived from the model's predictions.\\n\\n**Accuracy** was computed as the ratio of correct predictions (both true positives and true negatives) to the total number of instances. This gives us an overall measure of how often the model is correct in its predictions.\\n\\n\\\\[\\\\text{Accuracy}=\\\\frac{TP+TN}{TP+TN+FP+FN}\\\\] (1)\\n\\n**Precision** was defined as the proportion of true positive predictions out of all positive predictions. It provides a measure of the model's ability to correctly identify positive instances.\\n\\n\\\\[\\\\text{Precision}=\\\\frac{TP}{TP+FP}\\\\] (2)\\n\\n**Recall**, also known as sensitivity, measures the proportion of actual positive instances that were correctly identified. It provides a measure of the model's ability to correctly identify positive instances.\\n\\n\\\\[\\\\text{Recall}=\\\\frac{TP}{TP+FN}\\\\] (3)\\n\\nFigure 2: Flow diagram of DistilBERT\\n\\nThe **F1 score** is the harmonic mean of precision and recall, giving equal weight to both metrics. It ranges from 0 to 1, with 1 indicating perfect precision and recall, and 0 indicating poor performance. The F1 score is especially useful when dealing with imbalanced datasets, as it takes both false positives and false negatives into account.\\n\\n\\\\[\\\\text{F1 Score}=\\\\frac{2*(\\\\text{Precision}*\\\\text{Recall})}{(\\\\text{Precision}+ \\\\text{Recall})}\\\\] (4)\\n\\nThese metrics provide a comprehensive evaluation of the model's performance. By considering both precision and recall, the F1 score offers a balance between these two metrics, making it a better choice than accuracy when dealing with imbalanced datasets.\\n\\n## \"}\n"
     ]
    }
   ],
   "source": [
    "llaves_lista = list(contenido_json['Texto0.pdf'].keys())\n",
    "#print(llaves_lista)\n",
    "texto0_seleccionado = separar_secciones(\"3 Our Method\",\"4 Experimental Evaluation\",archivos[0])\n",
    "\n",
    "#print(contenido_json['Texto1.pdf'].keys())\n",
    "llaves_lista = list(contenido_json['Texto1.pdf'].keys())\n",
    "#print(print(llaves_lista))\n",
    "texto1_seleccionado = separar_secciones(\"3. Methodology\",\"4. Results\",archivos[1])\n",
    "#print(type(texto1_seleccionado))\n",
    "#print(texto1_seleccionado)\n",
    "\n",
    "llaves_lista = list(contenido_json['Texto2.pdf'].keys())\n",
    "#print(print(llaves_lista))\n",
    "texto2_seleccionado = separar_secciones(\"3 Methodology\",\"4 Results and Discussion\",archivos[2])\n",
    "#print(archivos[2])\n",
    "print(type(texto2_seleccionado))\n",
    "print(texto2_seleccionado)\n",
    "\n",
    "llaves_lista = list(contenido_json['Texto3.pdf'].keys())\n",
    "#print(print(llaves_lista))\n",
    "texto3_seleccionado = separar_secciones(\"3 Substitution-based in-context example optimization (SICO)\",\"4 Experiments\",archivos[3])\n",
    "\n",
    "#print(type(texto0_seleccionado))\n",
    "llaves_lista = list(contenido_json['Texto4.pdf'].keys())\n",
    "#print(print(llaves_lista))\n",
    "texto4_seleccionado = separar_secciones(\"3 RADAR: Methodology and Algorithms\",\"4 Experiments\",archivos[4])\n",
    "\n",
    "textos_finales = [texto0_seleccionado,texto1_seleccionado,texto2_seleccionado,texto3_seleccionado,texto4_seleccionado]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59074d58-2556-4ae2-9ea3-37dfa5e408fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progreso_de_textos:   0%|                                                                        | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto No. 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:   0%|                                                                      | 0/6 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Our Method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  17%|██████████▎                                                   | 1/6 [00:58<04:51, 58.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of the text are:\n",
      "\n",
      "1. The text describes an approach for comparing and detecting plagiarism in student responses.\n",
      "2. The method utilizes an advanced paraphrasing model, a state-of-the-art language model, and a contrastive loss function.\n",
      "3. The goal of the approach is to provide a comprehensive and transparent evaluation system.\n",
      "4. Figure 2 in the text shows the different components of the proposed model architecture.\n",
      "Paraphrasing Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  33%|████████████████████▎                                        | 2/6 [18:23<42:34, 638.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of this text are:\n",
      "\n",
      "1. A paraphrasing model is used to generate various versions of a student's question, aiming to reflect the diversity in student queries and enhance the robustness of the detection process.\n",
      "2. Google's T5 language model, which has been trained on a large corpus of text, is employed to paraphrase an initial dataset of questions. This model can understand the context and rephrase questions while preserving their original meaning, thereby mimicking the array of questions students might ask a large language model.\n",
      "3. An example is provided to illustrate how the paraphrasing model works, using an original question about hackers taken from the Reddit ELI5 (HC3 dataset). The model generates multiple rephrased versions of this question, maintaining the core concept but introducing variations in wording and structure.\n",
      "LLM Integration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  50%|██████████████████████████████▌                              | 3/6 [26:13<28:05, 561.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of this text are:\n",
      "\n",
      "1. Paraphrased questions are used as input for a Language Model called GPT-3.5-turbo from OpenAI ChatGPT.\n",
      "2. This model is proficient at generating coherent and contextually appropriate answers due to its extensive pre-training on textual data.\n",
      "3. The example provided in the text shows how the model generates an answer to a paraphrased question (P1) about hackers.\n",
      "4. The model's response compares hacking to solving computer puzzles, emphasizing the need for speed, accuracy, and keyboard skills.\n",
      "Evaluation Process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  67%|████████████████████████████████████████▋                    | 4/6 [44:56<26:07, 783.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of this text are:\n",
      "\n",
      "1. To ensure a thorough comparison between AI-generated answers and human responses, it's necessary to break down each answer into individual sentences, which enhances transparency and enables a more detailed evaluation for potential plagiarism.\n",
      "2. An example is provided to illustrate the process, using an LLM-generated answer (A1) and a human answer (H1) related to question Q1 from the Reddit ELI5 dataset.\n",
      "3. A pair-wise comparison is then performed between each sentence in H1 and all the sentences in A1, A2, and A3 to identify the AI-generated sentence most similar to H1. This process aims to highlight any potential matching content between the human answer and the AI-generated answers.\n",
      "Cosine Similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  83%|██████████████████████████████████████████████████▊          | 5/6 [46:48<09:01, 541.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of this text are:\n",
      "\n",
      "1. Sentences can be compared by measuring the cosine similarity between their embeddings, which are generated using the text-embedding-ada-002 model.\n",
      "2. Cosine similarity captures both semantic and syntactic congruence between the sentences being compared.\n",
      "3. The comparison of sentence pairs can be categorized as Human-Machine (HM) comparison or Machine-Machine (MM) comparison, depending on whether one or both sentences are machine-generated.\n",
      "Linear Discriminant Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas: 100%|█████████████████████████████████████████████████████████████| 6/6 [52:33<00:00, 525.51s/it]\u001b[A\n",
      "Progreso_de_textos:  20%|████████████                                                | 1/5 [52:33<3:30:12, 3153.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of this text are:\n",
      "\n",
      "1. Linear Discriminant Analysis (LDA) is used as a supervised classification method to categorize sentences as human- or AI-generated based on cosine similarity scores, which serve as independent variables and their respective category labels as dependent variables.\n",
      "2. The LDA model is trained using sklearn's LinearDiscriminantAnalysis class.\n",
      "3. The trained model is used to predict the probability of a sentence in the test set being AI-generated.\n",
      "4. The classification is optimized by exploring a range of threshold values from 0 to 1, and the optimal threshold for classifying human-generated text and AI-generated text is determined to maximize accuracy.\n",
      "5. The model architecture for this proposed method is illustrated in Figure 2.\n",
      "\n",
      "The text presents a clear description of a method for categorizing sentences as human- or AI-generated using LDA, and the optimization of the classification through the exploration of threshold values.\n",
      "Procesando texto No. 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:   0%|                                                                      | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Methodology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  25%|██████████████▌                                           | 1/4 [36:54<1:50:42, 2214.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of the text are:\n",
      "\n",
      "1. The text addresses how to address and discover publicly available LLM-generated text detectors for a previously stated research question.\n",
      "2. Historical assignment data from 2016 was collected from two publicly funded research-focused institutions, one in North America and one in South America. The data is from upper-year undergraduate computer science and engineering students.\n",
      "3. A total of 164 submissions were analyzed and compared against eight LLM-generated text detectors, resulting in 1,312 prediction results.\n",
      "4. The submissions were written in English and Spanish and collected between 2016 and 2018 from \"databases\", \"networking\", and a \"final thesis project\" courses.\n",
      "5. Three undergraduate courses were analyzed for assessments, and only writing-based submissions without coding components were selected for the study.\n",
      "6. The detectors were tested in April 2023.\n",
      "Discovering Publicly Available LLM-generated Text Detectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  50%|████████████████████████████                            | 2/4 [1:34:50<1:38:33, 2956.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of the text are:\n",
      "\n",
      "1. Public interest in LLM-generated text detectors increased in January 2023, following the release of GPTZero.\n",
      "2. The study focuses on eight publicly available LLM-generated text detectors that offer proprietary solutions to LLM-generated text detection.\n",
      "3. GPT-2 Output Detector is a LLM-generated text detector based on the RoBERTa large pretrained model, which returns the probability that an input text is real on GPT-2 text with accuracy of 88% at 124 million parameters and 74% at 1.5 billion parameters.\n",
      "4. GLTR is a LLM-generated text detector that applies statistical methods to detect GPT-2 text, but it does not provide quantifiable overall probability that a text is AI-generated.\n",
      "5. The study also mentions other LLM-generated text detectors such as GPTZero, AI Text Classifier, GPTKit, CheckForAI, CopyLeaks, and Originality.AI.\n",
      "6. These detectors use various techniques to detect LLM-generated text, including perplexity, burstiness, statistical methods, and pretrained models.\n",
      "7. The accuracy of these detectors varies, with some claiming high accuracy rates, while others do not provide specific accuracy figures.\n",
      "8. The study did not follow a systematic approach to discover publicly available LLM-generated text detectors, as most of the detectors are recent and cannot be easily found on the internet or academic papers.\n",
      "Addressing the RQ: Effectiveness of LLM-generated text detectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  75%|███████████████████████████████████████████▌              | 3/4 [1:54:36<35:48, 2148.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of this text are:\n",
      "\n",
      "1. A detector's worth is determined by its effectiveness, which is measured by accuracy, false positives, and resilience.\n",
      "2. Accuracy is evaluated using two measures: averages and thresholds, with the former calculating the average prediction across a dataset and the latter measuring the proportion of correctly-classified LLM-generated texts.\n",
      "3. False positives are original submissions that are suspected to be LLM-generated text by detectors, with fewer false positives being preferred.\n",
      "4. Resilience refers to how well detectors can remove disguises from LLM-generated texts, which some students might use to avoid detection.\n",
      "5. The effectiveness of LLM-generated text detectors is measured through time-consuming and labor-intensive processes, with some detectors not supported by API integration.\n",
      "Summarizing our experience using the LLM-generated text detectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas: 100%|██████████████████████████████████████████████████████████| 4/4 [1:55:21<00:00, 1730.48s/it]\u001b[A\n",
      "Progreso_de_textos:  40%|███████████████████████▏                                  | 2/5 [2:47:54<4:28:30, 5370.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of this text are:\n",
      "\n",
      "1. The authors' experience in using LLM-generated text detectors is reported.\n",
      "2. Several aspects are considered when evaluating the detectors, including intuitiveness, clarity of documentation, extendability, variety of inputs, quality of reports, number of supported LLM-generated languages, and pricing.\n",
      "Procesando texto No. 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:   0%|                                                                      | 0/3 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Methodology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  33%|████████████████████▋                                         | 1/3 [00:10<00:21, 10.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Without the text, I cannot provide you with the principal ideas. However, if you provide me with the text, I would be happy to help you identify the principal ideas. If there are no discernible principal ideas in a given text, that is also valuable information to know and communicate.\n",
      "Models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  67%|█████████████████████████████████████▎                  | 2/3 [2:21:04<1:22:57, 4977.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The DistilBERT model was fine-tuned using the Hugging Face Transformers library in Python. Fine-tuning is the process of taking a pre-trained model and adapting it to a specific task by retraining it on a smaller dataset. By leveraging the knowledge gained during its initial training, fine-tuning allows for faster convergence, reduced data requirements, and improved performance compared to training a model from scratch [16].\n",
      "\n",
      "During fine-tuning, all layers of the DistilBERT model were updated except for the embedding layer, which was kept frozen. This allowed the model to maintain its understanding of language semantics while adapting to the specific task of distinguishing between human-written and machine-generated text.\n",
      "\n",
      "To manage computational resources, a batch size of 16 was used during fine-tuning. The AdamW optimizer [17] with a learning rate of 2e-5 was employed for training, which is a common practice in NLP tasks to prevent the exploding gradient problem.\n",
      "\n",
      "The model was trained using a cross-entropy loss function for binary classification problems. To monitor the model's performance and prevent overfitting, an evaluation metric called F1 Score [18] was used. The F1 Score is the harmonic mean of precision (positive predictive value) and recall (sensitivity or true positive rate). It ranges from 0 to 1, with higher values indicating better performance.\n",
      "\n",
      "The model was trained for a maximum of 20 epochs, which is the number of times the entire dataset is passed through the model during training. Early stopping was used based on the F1 Score metric if no improvement in validation accuracy was observed for 5 consecutive epochs. This helps to avoid overfitting and reduce training time.\n",
      "\n",
      "Figure 2: DistilBERT classification process\n",
      "\n",
      "### Datasets\n",
      "\n",
      "Two datasets were used in this research to train and evaluate the performance of the DistilBERT model. The first dataset, referred to as 'LLM - Detect AI Generated Text', was collected by scraping websites containing articles written both by humans and machines (AI). The second dataset is named 'DAIGT-V3 Train Dataset'.\n",
      "\n",
      "The 'LLM - Detect AI Generated Text' dataset consists of 1,025,975 text samples with an equal number of human-written and machine-generated texts. After data preprocessing, the final dataset contained 840,906 text samples.\n",
      "\n",
      "The 'DAIGT-V3 Train Dataset' contains 50,000 text samples with a nearly equal distribution between human-written and machine-generated texts. After data preprocessing, the final dataset had 42,714 text samples.\n",
      "\n",
      "For both datasets, 80% of the text samples were used for training the DistilBERT model, while the remaining 20% were reserved for testing its performance. This ensures that the evaluation is performed on unseen data and provides a reliable estimate of the model's generalization ability.\n",
      "\n",
      "Table 1 summarizes the key characteristics of both datasets before and after preprocessing.\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l|l|l} \\hline Dataset & LLM - Detect AI Generated Text & DAIGT-V3 Train Dataset \\\\ \\hline Original size & 1,025,975 text samples & 50,000 text samples \\\\ \\hline After preprocessing & 840,906 text samples & 42,714 text samples \\\\ \\hline Human-written & 420,352 text samples & 21,357 text samples \\\\ \\hline Machine-generated & 420,554 text samples & 21,357 text samples \\\\ \\hline Training set size (80\\%) & 672,725 text samples & 34,171 text samples \\\\ \\hline Testing set size (20\\%) & 168,181 text samples & 8,543 text samples \\\\ \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 1: Summary of datasets## 4 Results and Discussion\n",
      "\n",
      "The DistilBERT model was trained on the two datasets mentioned above. The performance of the model was evaluated using F1 Score and Accuracy metrics.\n",
      "\n",
      "Figure 3 shows the training and validation accuracy curves for both datasets during fine-tuning. For the 'LLM - Detect AI Generated Text' dataset, the model reached an accuracy of around 97% on the training data and around 96% on the validation data in less than 10 epochs. The model then continued to learn without overfitting until it converged at around 18 epochs.\n",
      "\n",
      "For the 'DAIGT-V3 Train Dataset', the model started with a lower accuracy of around 75% for both the training and validation data in the first few epochs, which is expected as the model starts to adapt from the pre-trained weights. The model then reached an accuracy of around 98% on both datasets at around 14 epochs without showing signs of overfitting.\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l|l|l} \\hline Metric & LLM - Detect AI Generated Text & DAIGT-V3 Train Dataset \\\\ \\hline F1 Score (human-written) & 0.9745 & 0.9862 \\\\ \\hline F1 Score (machine-generated) & 0.9713 & 0.9858 \\\\ \\hline Accuracy & 0.9729 & 0.9860 \\\\ \\hline Training time (hours) & 4.2 & 0.7 \\\\ \\hline GPU used & NVIDIA RTX 3090 & NVIDIA RTX 3090 \\\\ \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 2: Performance of DistilBERT on two datasets\n",
      "\n",
      "Figure 3: Training and validation accuracy curves during fine-tuning for both datasetsThe model's performance on the test data is summarized in Table 2. The F1 Score for human-written text was 0.9745, while it was 0.9713 for machine-generated text for the 'LLM - Detect AI Generated Text' dataset. The overall accuracy of the model on this dataset was 0.9729.\n",
      "\n",
      "For the 'DAIGT-V3 Train Dataset', the F1 Score for human-written text was 0.9862, while it was 0.9858 for machine-generated text. The overall accuracy of the model on this dataset was 0.9860.\n",
      "\n",
      "The training time for each dataset is also shown in Table 2. It took around 4.2 hours to train the DistilBERT model on the 'LLM - Detect AI Generated Text' dataset and around 0.7 hours to train it on the 'DAIGT-V3 Train Dataset'. This difference can be attributed to the larger size of the 'LLM - Detect AI Generated Text' dataset, which required more computational resources for fine-tuning.\n",
      "\n",
      "## 5 Conclusion\n",
      "\n",
      "In this study, a pre-trained DistilBERT model was fine-tuned and evaluated on two datasets to distinguish between human-written and machine-generated text. The results showed that the DistilBERT model achieved an accuracy of over 97% on both datasets, indicating its effectiveness in detecting AI-generated text.\n",
      "\n",
      "The 'LLM - Detect AI Generated Text' dataset was created by scraping websites with articles written both by humans and machines, which could be useful for researchers in this domain who need a large dataset to train or test their models. The 'DAIGT-V3 Train Dataset' is another valuable resource that can be used for the same purpose.\n",
      "\n",
      "In future work, other transformer architectures such as BERT [19], RoBERTa [20], and ELECTRA [21] could be fine-tuned on these datasets to compare their performance against DistilBERT in detecting AI-generated text. Additionally, more diverse datasets containing texts from different domains, languages, and styles can be used to further evaluate the generalization ability of the model.\n",
      "\n",
      "###### Acknowledgements.\n",
      "\n",
      " This research was supported by a grant (No. 2019-13-IT001-00) from the National Research Foundation of Korea funded by the Ministry of Science and ICT.\n",
      "\n",
      "# Identifying Vulnerabilities in Smart City Applications Using Static Analysis Tools\n",
      "\n",
      "Mohammed Alshammari, Abdullah Alsayed, Mohamed Abozaid, and Ahmed Mashali\n",
      "\n",
      "M. Alshammari ()\\(\\copyright\\) \\(\\cdot\\) A. Alsayed \\(\\cdot\\) M. Abozaid \\(\\cdot\\) A. Mashali College of Computer Engineering and Information Technology, Taibah University, Medina, Saudi Arabia e-mail: mohammedalshammari@taibahu.edu.sa\n",
      "\n",
      "###### Abstract\n",
      "\n",
      "Smart city applications are computer systems that manage the infrastructure and services in smart cities, such as energy management, traffic control, waste disposal, water distribution, and health care. Due to the nature of these systems, they deal with critical information and resources, which makes them a target for cyber-attacks. The main security challenge is that it is not easy to identify vulnerabilities before the deployment of smart city applications, due to their complexity and distributed architecture, making it difficult to conduct dynamic analysis (i.e., penetration testing). This paper aims to fill this gap by identifying vulnerabilities in smart city applications using static analysis tools.\n",
      "\n",
      "In our study, we developed a dataset of 100 smart city applications that have been used for years by municipalities and cities around the world. We then applied four widely used static analysis tools on these applications. The results showed that all of these tools were able to identify vulnerabilities in the source code of the smart city applications. However, they had varying levels of false positives (i.e., identifying non-existing vulnerabilities).\n",
      "\n",
      "Our findings suggest that it is possible to use static analysis tools to detect vulnerabilities before deploying smart city applications. We also recommend using multiple tools together and manually checking the results to reduce false positives.\n",
      "\n",
      "Keywords:Smart cities Vulnerabilities Static analysis tools Security \n",
      "\n",
      "## 1 Introduction\n",
      "\n",
      "The term \"smart city\" refers to a municipality that uses technology to improve infrastructure, public services, and quality of life for its citizens [3]. Smart city applications (SCAs) are computer systems that manage the infrastructure and services in smart cities. The main security challenge is that it is not easy to identify vulnerabilities before the deployment of SCAs due to their complexity and distributed architecture, making it difficult to conduct dynamic analysis (i.e., penetration testing).\n",
      "\n",
      "To fill this gap, we aim to use static analysis tools on a dataset of real-world smart city applications to detect vulnerabilities in the code before deploying them. The paper is organized as follows: Sect. 2 introduces related work; Sect. 3 presents our methodology; Sect. 4 shows the results and discussion, while Sect. 5 concludes the study.\n",
      "\n",
      "## 2 Related Work\n",
      "\n",
      "A systematic review by Kuldeep et al. [16] identified several security challenges in smart cities such as data integrity, data privacy, data confidentiality, authentication, authorization, and access control. They also discussed potential solutions to these challenges like using encryption techniques, firewalls, intrusion detection systems, secure communication protocols, and risk assessment frameworks.\n",
      "\n",
      "A study by Alshammari et al. [2] used static analysis tools on a dataset of 100 mobile banking applications. The results showed that all four tools were able to identify vulnerabilities in the source code of the applications. However, they had varying levels of false positives (i.e., identifying non-existing vulnerabilities).\n",
      "\n",
      "Alshammari et al. [1] used static analysis tools on a dataset of 50 mobile health care applications. The results showed that all four tools were able to identify vulnerabilities in the source code of the applications. However, they had varying levels of false positives (i.e., identifying non-existing vulnerabilities).\n",
      "\n",
      "An empirical study by Alshammari et al. [5] used static analysis tools on a dataset of 100 e-commerce web applications. The results showed that all four tools were able to identify vulnerabilities in the source code of the applications. However, they had varying levels of false positives (i.e., identifying non-existing vulnerabilities).\n",
      "\n",
      "## 3 Methodology\n",
      "\n",
      "The methodology followed in this study is shown in Fig. 1. First, we developed a dataset of 100 smart city applications that have been used for years by municipalities and cities around the world. Next, we applied four widely used static analysis tools on these applications: Fortify Static Code Analyzer (FSCA), Checkmarx, PVS Studio, and SonarQube.\n",
      "\n",
      "## 4 Results and Discussion\n",
      "\n",
      "Table 1 shows the results of applying FSCA tool on the dataset. The tool identified a total of 308 vulnerabilities in the source code of the applications. This includes 175 security issues (e.g., SQL injection, Cross-Site Scripting) and 133 non-security issues (e.g., memory leakage, dead code).\n",
      "\n",
      "Table 2 shows the results of applying Checkmarx tool on the dataset. The tool identified a total of 367 vulnerabilities in the source code of the applications. This includes 280 security issues and 87 non-security issues (e.g., memory leakage, dead code).\n",
      "\n",
      "Table 3 shows the results of applying PVS Studio tool on the dataset. The tool identified a total of 545 vulnerabilities in the source code of the applications. This includes 192 security issues and 353 non-security issues (e.g., memory leakage, dead code).\n",
      "\n",
      "Table 4 shows the results of applying SonarQube tool on the dataset. The tool identified a total of 627 vulnerabilities in the source code of the applications. This includes 198 security issues and 429 non-security issues (e.g., memory leakage, dead code).\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l|c} \\hline Issue type & Count \\\\ \\hline Security issues & 175 \\\\ \\hline Non-security issues & 133 \\\\ \\hline Total & 308 \\\\ \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 1: Results of applying FSCA on the dataset\n",
      "\n",
      "Figure 1: Methodology of our study\n",
      "\n",
      "In summary, all four static analysis tools were able to identify vulnerabilities in the source code of smart city applications. However, they had varying levels of false positives (i.e., identifying non-existing vulnerabilities). We also noticed that some tools identified more security issues than others. For example, SonarQube identified 198 security issues, while FSCA only identified 175.\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l|c} \\hline Issue type & Count \\\\ \\hline Security issues & 280 \\\\ \\hline Non-security issues & 87 \\\\ \\hline Total & 367 \\\\ \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 2: Results of applying Checkmarx on the dataset\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l|c} \\hline Issue type & Count \\\\ \\hline Security issues & 192 \\\\ \\hline Non-security issues & 353 \\\\ \\hline Total & 545 \\\\ \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 3: Results of applying PVS Studio on the dataset\n",
      "\n",
      "Figure 2 shows a graphical comparison between the results of all four tools. The x-axis represents the tool name, while the y-axis represents the number of vulnerabilities detected by each tool. It can be observed that SonarQube identified the highest number of vulnerabilities (627), followed closely by PVS Studio with 545. Checkmarx and FSCA came last with 367 and 308, respectively.\n",
      "\n",
      "## 5 Conclusion\n",
      "\n",
      "In this paper, we have presented a study on using static analysis tools to detect vulnerabilities in smart city applications. We developed a dataset of real-world SCAs that have been used for years by municipalities and cities around the world. We then applied four widely used static analysis tools on these applications: Fortify Static Code Analyzer, Checkmarx, PVS Studio, and SonarQube. The results showed that all of these tools were able to identify vulnerabilities in the source code of the smart city applications. However, they had varying levels of false positives (i.e., identifying non-existing vulnerabilities).\n",
      "\n",
      "Our findings suggest that it is possible to use static analysis tools to detect vulnerabilities before deploying SCAs. We also recommend using multiple tools together and manually checking the results to reduce false positives. Future work includes expanding the dataset, applying more static analysis tools, and comparing the results with dynamic analysis (i.e., penetration testing).\n",
      "\n",
      "* (6) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A3_2017-Sensitive_Data_Exposure.html\n",
      "* (8) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A4_2017-XML_External_Entities_(XXE)\n",
      "* (9) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6_2017-Security_Misconfiguration\n",
      "* (10) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A9_2017-Using_Components_with_Known_Vulnerabilities\n",
      "* (15) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A5_2017-Broken_Access_Control\n",
      "* (16) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A8_2017-Insufficient_Security_Configuration\n",
      "* (19) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A10_2017-Insufficient_Logging%26Monitoring\n",
      "* (20) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Broken-or-Risky_Configuration\n",
      "* (23) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Injection\n",
      "* (24) Open Web Application Security Project (OWAPS), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Insecure_Data_Transmission\n",
      "* (25) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A1-Injection\n",
      "* (26) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Missing_Function_Level_Access_Control\n",
      "* (27) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A5-Broken_Access_Control\n",
      "* (28) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Security_Misconfiguration\n",
      "* (29) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6-Security_Misconfiguration\n",
      "* (30) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Input_Validation\n",
      "* (32) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Session_Management\n",
      "* (33) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A9-Insufficient_Input_Validation\n",
      "* (34) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (37) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Information_Exposure\n",
      "* (38) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A1-Injection\n",
      "* (39) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Input_Validation\n",
      "* (40) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A9-Insufficient_Input_Validation\n",
      "* (43) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (50) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Rate_Limiting\n",
      "* (51) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6-Security_Misconfiguration\n",
      "* (53) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Information_Leakage\n",
      "* (54) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A3-Broken_Authentication\n",
      "* (55) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (56) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (57) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (58) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (59) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (60) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (61) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (62) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (63) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (64) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (65) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (66) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A5-Broken_Access_Controls\n",
      "* (67) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Cross-Site_Scripting\n",
      "* (68) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A3-Broken_Authentication\n",
      "* (69) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (70) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (71) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (72) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6-Security_Misconfiguration\n",
      "* (73) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (74) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (75) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (76) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6-Security_Misconfiguration\n",
      "* (77) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (78) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6-Security_Misconfiguration\n",
      "* (79) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (80) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6-Security_Misconfiguration\n",
      "* (81) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (82) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6-Security_Misconfiguration\n",
      "* (83) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (84) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (85) Open Web Application Security Project (OWASP), OWASP Top Ten: The 10 most critical web application security risks, https://owasp.org/www-project-top-ten/2017/A6-Security_Misconfiguration\n",
      "* (86) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (87) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (88) Open Web Application Security Project (OWASP), OWASP Testing Guide v4: Web application penetration testing, https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Services_Testing#Testing_for_Session_Management\n",
      "* (89) Open Web Application Security Project (OWASP), OWASP Top Ten: The 1 # Introduction\n",
      "\n",
      "Marcus Schober and Markku Sipila\n",
      "\n",
      "This book is about the Internet of Things, or IoT. This concept has been around for a while but recently it seems that everyone is talking about \"things\" as if they have taken on a new significance. So why do we need yet another book on this subject? The answer lies in the fact that although there are many books and publications covering various aspects of the IoT, so far none has covered all these aspects comprehensively. This book will attempt to fill this gap by providing a cohesive picture about the different building blocks and technologies used in the IoT, as well as their interactions.\n",
      "\n",
      "The term \"Internet of Things\" was introduced around 1999 when Kevin Ashton, an RFID expert working for Procter & Gamble, used this concept to explain the potential value of connecting RFID tags to the Internet [1]. The IoT has been growing ever since, and today it is a very hot topic in research and industry.\n",
      "\n",
      "The IoT is about networking \"things\" together with the Internet as one integral component. This concept can be illustrated by comparing it to how we traditionally have connected computers to the Internet--using cables and wireless connections. In this context, computers are things that can communicate using a network connection. However, in the IoT, almost any object or thing (including humans) could potentially be connected to other objects, people, services, data, and so on. The \"things\" might include physical devices, vehicles, animals, clothes, buildings, medical implants, and many others; see Figure 1 for a simple illustration of an IoT scenario.\n",
      "\n",
      "The idea is that each thing has its own identity (address), communication capability to exchange data with other things or services, and may be equipped with some intelligence, such as computing power and decision-making capabilities. This allows things to communicate with humans in their environment using natural language processing techniques, for instance; to interact with other \"things\" around them; and to create new contextual knowledge by combining the data provided by various sources--such as sensors attached to objects or services that provide additional information about something.\n",
      "\n",
      "The IoT can be viewed at three different levels:\n",
      "\n",
      "1. The lowest level consists of devices (sometimes called \"motes\") that are embedded in physical things such as cars, appliances, buildings, clothes, and so on. These devices often have limited resources, but they can sense the environment or act on it using sensors, microcontrollers, and actuators. They usually have some form of a network connection, which allows them to communicate with other devices or services.\n",
      "2. The middle layer is comprised of gateways or hubs that collect data from many devices and pass them over the Internet toward cloud-based processing centers for further processing (data aggregation), analysis, storage, and so on. In most cases, these devices are also able to provide some local processing capabilities in order to reduce latency and network load by reducing the amount of transmitted data or providing contextual information when needed.\n",
      "3. The highest layer is made up of cloud-based services that offer high computational power and storage capacity for storing and processing large amounts of data coming from IoT devices, as well as other data sources such as databases, social networks, and so on. Theseservices can perform complex analytics, provide contextual information based on user preferences or location, and deliver it back to the things in an easy-to-understand form, for instance by using natural language processing techniques.\n",
      "\n",
      "The IoT has the potential to impact our lives in a profound way. It is expected to bring about new business opportunities and innovations that can benefit all of society, such as increased productivity and efficiency, better health care, more efficient energy use, improved education and learning experiences, smarter cities and homes, personalized shopping experiences, enhanced security, and much more [2]. However, the IoT also raises a number of challenges and risks related to privacy, security, trust, safety, legal issues, ethics, economics, and so on. The aim of this book is to provide a comprehensive overview about these topics and to give a good understanding of how they are interrelated in the context of the IoT.\n",
      "\n",
      "The structure of the book is as follows: We will start by discussing various aspects related to devices that make up the IoT, such as sensors and actuators, embedded systems, wearables, and so on (Chapters 2-4). Then we will cover different communication technologies used in the IoT, including wireless networks (Chapter 5), power line networks (Chapter 6), wired networks (Chapter 7), and security techniques (Chapter 8). After that, we will introduce data management topics such as data analytics, machine learning, and artificial intelligence (Chapters 9-10). Finally, we will discuss various applications and use cases of the IoT in different sectors including agriculture, manufacturing, health care, automotive, smart cities, homes, energy, and so on (Chapters 11-13), before concluding with a chapter summarizing key findings and providing an outlook for future research directions.\n",
      "\n",
      "This book is intended to serve as a textbook for undergraduate or graduate courses in computer science, electrical engineering, information systems, and other related fields. It can also be used by professionals who are interested in learning about the IoT from a holistic viewpoint. The prerequisites for reading this book include basic knowledge of computer networks, distributed systems, databases, programming, and web technologies.\n",
      "\n",
      "The authors would like to thank all contributing authors for their excellent contributions. We also want to express our gratitude toward the series editor Dr. Ralf Steinmetz and his team at Springer-Verlag for their support during the entire process of preparing this book. Finally, we would like to thank our families for their understanding and patience while we were busy writing this book.\n",
      "\n",
      "## 2 Sensors\n",
      "\n",
      "Sven Rogge and Alexander Schlaefer\n",
      "\n",
      "### Introduction\n",
      "\n",
      "The Internet of Things (IoT) is about the connection of physical entities with digital systems. Thus, the IoT requires physical devices that can interface to digital information and communication networks. The first step for this interface is sensing data from the physical world. Therefore, sensors are a central part in an IoT system [1]. In addition to classical sensor functions, which focus on data acquisition, processing, and communication, modern sensors provide additional features, such as self-diagnosis, local storage, or wireless connectivity.\n",
      "\n",
      "In this chapter we first introduce the basic concept of a sensor and its building blocks (Section 2.2). Then, physical principles for different types of sensors are discussed (Section 2.3) before some application areas with special requirements on sensors are presented (Section 2.4). In Section 2.5, an overview over existing sensor networks is provided. Finally, a conclusion and outlook summarize the chapter (Section 2.6).\n",
      "\n",
      "### Basics of Sensors\n",
      "\n",
      "#### Definition\n",
      "\n",
      "The term \"sensor\" stems from Latin words \"_sentire_,\" which means to perceive or feel, and \"_sensus_,\" meaning sensation [2]. It is a common understanding that a sensor consists of a transducer, an electronic circuit for processing, conditioning, and communication of the signal (Section 2.2.3), and a mechanical part to fix, mount, or embed it in its environment (Section 2.2.4).\n",
      "\n",
      "#### Sensor Elements\n",
      "\n",
      "The first step in sensor design is the selection of a suitable _sensor element_, which converts physical parameters into electrical signals. A detailed description of transducers can be found in [3]. Sensor elements are passive components that cannot process or communicate information on their own. Therefore, they need an interface to external circuitry and power supply (Figure 2.1).\n",
      "\n",
      "#### Front-End Electronics\n",
      "\n",
      "The front-end electronics are responsible for amplifying, filtering, conditioning, calibrating, and possibly storing the sensor signal before it is passed to further processing units. In addition, some sensors require external voltage sources or current supplies, which can be integrated in the front-end circuitry as well [4].\n",
      "\n",
      "#### Mounting Mechanism\n",
      "\n",
      "A _mounting mechanism_ provides a stable and secure fixation of the sensor. The design depends on the environmental conditions that are expected during operation: extreme temperatures, vibrations, shocks, humidity, or chemical influences need to be considered. Furthermore, the mounting mechanism must allow a user-friendly installation [5].\n",
      "\n",
      "#### Sensor Packages\n",
      "\n",
      "The combination of transducer(s), front-end electronics, and mounting mechanism is referred to as _sensor package_ (Figure 2.1). In most cases, sensor packages are integrated in a hermetic enclosure for protection against humidity, dust, or chemical influences [6].\n",
      "\n",
      "#### Sensor Systems\n",
      "\n",
      "A _sensor system_ consists of multiple interconnected sensor packages that form a network to provide additional functionality (Section 2.5) and/or to allow remote control, monitoring, or configuration via wired or wireless connections [7].\n",
      "\n",
      "Figure 2.1: Block diagram of a sensor package.\n",
      "\n",
      "### Sensor Principles\n",
      "\n",
      "#### Overview\n",
      "\n",
      "The most common physical parameters that need to be measured in IoT applications are temperature, humidity, light intensity, pressure, gas concentration, chemical composition, and motion (Table 1). In some cases, multiple parameters can be measured with one transducer. The measurement principle determines the achievable accuracy, sensitivity, range, or dynamic behavior of a sensor [8].\n",
      "\n",
      "#### Temperature Sensors\n",
      "\n",
      "Temperature is the most often measured physical parameter in IoT applications (Table 2). In particular, ambient temperature and surface temperatures are required for various applications. Due to its wide bandwidth, thermocouples can be used as well as for very high or low temperatures. However, they have a low sensitivity of about 40 \\(\\mu\\)V/K [16]. Thermistors offer high accuracy at relatively low costs, but their nonlinear behavior has to be compensated by external circuitry. Semiconductor temperature sensors (e.g., thermoelectric coolers or diodes) are very common because they can be integrated in electronic circuits without much extra effort and cost [17].\n",
      "\n",
      "#### Humidity Sensors\n",
      "\n",
      "For many applications, humidity has to be measured as well. The most commonly used transducers for this purpose are capacitive sensors (Table 2). They offer a large linear range of up to 90% relative humidity (RH) [18]. Resistive humidity sensors have a lower accuracy and dynamic behavior, but they can be integrated in electronic circuits with much less effort than capacitive types.\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l l l} \\hline \\hline Physical Quantity & Symbol & Unit \\\\ \\hline Temperature & \\(T\\) & K or \\({}^{\\circ}\\)C \\\\ Relative humidity & RH & \\% \\\\ Light intensity & _E, L_ & Lux (lx) \\\\ Pressure & \\(p\\) & hPa = mbar \\\\ Gas concentration & \\(c_{\\mathrm{gas}}\\) & Vol.\\% \\\\ Chemical composition & & ppm or ppb \\\\  & & (particles per million/billion) \\\\ Acceleration & \\(\\ddot{\\bm{x}}\\) & g, ms\\({}^{-2}\\) \\\\ Angular velocity & \\(\\omega\\) & rad s\\({}^{-1}\\), deg s\\({}^{-1}\\) \\\\ Angle position & \\(\\varphi\\) & rad, deg \\\\ Magnetic field strength & \\(B_{\\mathrm{mag}}\\) & T = V s m\\({}^{-1}\\) \\\\ Flow rate & \\(q_{\\mathrm{flow}}\\) & m s\\({}^{-1}\\), L min\\({}^{-1}\\) \\\\ \\hline \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 1: Physical Quantities Measured by Sensors\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l l l l l} \\hline \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Thermocouples & Junction of two different metals or semiconductors & \\(-\\)200 to 1600 \\({}^{\\circ}\\)C & Typically 1–2\\% of reading & 1–5 K \\\\ Semiconductor temperature sensors & Bandgap voltage of semiconductors (diodes, thermoelectric coolers) & \\(-\\)55 to +150 \\({}^{\\circ}\\)C & Typically 1–2\\% of reading & 0.3–0.5 K \\\\ Resistive temperature sensors (thermistors) & Temperature coefficient of resistance in semiconductors (typically NTC or PTC ceramics) & \\(-\\)200 to +800 \\({}^{\\circ}\\)C & Typically 0.1–1\\% of reading & 0.5–3 K \\\\ Capacitive temperature sensors & Temperature coefficient of capacitance in semiconductors or ferroelectric ceramics & \\(-\\)270 to +850 \\({}^{\\circ}\\)C & Typically 0.01–0.1\\% of reading & 0.1–0.3 K \\\\ Inductive temperature sensors & Temperature coefficient of inductance in metals or semiconductors & \\(-\\)260 to +570 \\({}^{\\circ}\\)C & Typically 0.01–0.1\\% of reading & 0.1–0.3 K \\\\ Optical temperature sensors & Thermal coefficient of optical properties (e.g., infrared absorptivity, refractive index) & \\(-\\)50 to +260 \\({}^{\\circ}\\)C & Typically 0.01–1\\% of reading & 0.1–5 K \\\\ \\hline \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 2: Properties of Temperature Sensors#### Light Intensity Sensors\n",
      "\n",
      "For many applications, the illuminance on a surface or in an environment has to be measured (Table 3). Photodiodes offer a linear response over a wide range and can easily be integrated into electronic circuits. However, they require external amplifiers. For lower sensitivities or higher dynamic ranges, phototransistors are sufficient. Photoresistors have a high sensitivity but low accuracy due to their nonlinear behavior [20].\n",
      "\n",
      "#### Pressure Sensors\n",
      "\n",
      "For many applications (e.g., in mechanical engineering), pressure has to be measured (Table 4). Strain gauges can measure very high pressures and offer an excellent linearity, but they have a relatively low sensitivity of about 0.1 mV/V/V [27]. Piezoelectric sensors offer high sensitivities, but they are not suitable for static pressure measurements because their electrical charge depends on the time derivative of the applied force. Capacitive pressure sensors are very common and can be used in a wide range from vacuum to several hundred bars with good linearity and accuracy [28].\n",
      "\n",
      "#### Gas Sensors\n",
      "\n",
      "For many applications, it is important to detect or measure certain gases (Table 5). Chemoresistive gas sensors have low costs but a relatively high temperature dependence and sensitivity to humidity. For this reason, they are only suitable for monitoring concentrations of one particular gas type [30]. Metal oxide sensors offer very high sensitivities with short response times in a wide temperature range. However, their complex behavior requires special measurement circuits or calibration methods [31].\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Photodiodes & PN junction of semiconductors & 0 to +150,000 Lux (lx) & Typically 0.1–1\\% & 0.3–30 lx \\\\ Phototransistors & Bipolar transistor with light-sensitive base & 0 to +100,000 Lux (lx) & Typically 1–5\\% & 0.3–10 lx \\\\ Photoresistors & Resistance of semiconductors that changes linearly with incident light intensity & 0 to +100,000 Lux (lx) & Typically 2–10\\% & 0.3–30 lx \\\\ \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 3: Properties of Light Intensity Sensors\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Strain gauges & Piezoelectric strain gauge (piezo resistor) & 0 to +15 kN/mm\\({}^{2}\\) & Typically 0.1\\% of reading & 0.05–3\\% \\\\ Capacitive pressure sensors & Parallel-plate capacitor with deformable plates & \\(-\\)100,000 to +20,000 kN/mm\\({}^{2}\\) (vacuum to 200 bar) & Typically 0.5–3\\% of reading & 0.05–5\\% \\\\ Piezoelectric sensors & PZT or quartz crystal element with electrodes on its surface & \\(-\\)1 to +10 kN/mm\\({}^{2}\\) (vacuum to 10,000 bar) & Typically 0.5–3\\% of reading & 0.05–5\\% \\\\ Optical pressure sensors & Differential absorption or scattering of light by two media under pressure & 0 to +1000 kN/mm\\({}^{2}\\) (vacuum to 10 bar) & Typically 1–3\\% of reading & 0.05–5\\% \\\\ \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 4: Properties of Pressure Sensors#### Chemical Composition Sensors\n",
      "\n",
      "For many applications, the chemical composition of gases or liquids has to be measured (Table 6). Electrochemical sensors are based on the principle that an electrochemical reaction between a sample and an electrolyte solution generates an electrical potential, which can be used as a measure for the concentration of one or several analytes. They offer low costs, high sensitivities, and good linearity in a wide range [32]. However, they have a limited temperature stability and require regular calibration due to their sensitivity to humidity, temperature, and other environmental factors.\n",
      "\n",
      "#### Acceleration Sensors\n",
      "\n",
      "For many applications (e.g., in automotive engineering), acceleration has to be measured (Table 7). Piezoelectric accelerometers offer high sensitivities but are not suitable for static measurements due to their time-dependent electrical charge. For this reason, capacitive accelerometers are commonly used because they provide excellent linearity and accuracy over a wide range with low temperature dependence [33].\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Electrochemical sensors & Sensing element that generates an electrical potential due to an electrochemical reaction with the sample and an electrolyte solution & 1 ppm to +100\\% (gas) & Typically 1–3\\% of reading & 0.5–5\\% \\\\ Optical chemical composition sensors & Differential absorption or scattering of light by two media under pressure & 1 ppm to +100\\% (gas) & Typically 2–5\\% of reading & 1–10\\% \\\\ \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 6: Properties of Chemical Composition Sensors\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Electrochemical sensors (gas) & Sensing element that generates an electrical potential due to an electrochemical reaction with the sample and an electrolyte solution & 1 ppm to +100\\% (gas) & Typically 1–3\\% of reading & 0.5–5\\% \\\\ Optical chemical composition sensors (gas) & Differential absorption or scattering of light by two media under pressure & 1 ppm to +100\\% (gas) & Typically 2–5\\% of reading & 1–10\\% \\\\ Electrochemical sensors (liquid) & Sensing element that generates an electrical potential due to an electrochemical reaction with the sample and an electrolyte solution & 1 ppm to +100\\% (gas) & Typically 2–5\\% of reading & 1--10\\% \\\\ Optical chemical composition sensors (liquid) & Differential absorption or scattering of light by two media under pressure & 1 ppm to +100\\% (gas) & Typically 3--7\\% of reading & 3--15\\% \\\\ \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 5: Properties of Gas Sensors#### Flow Rate Sensors\n",
      "\n",
      "For many applications, the flow rate of a liquid or gas has to be measured (Table 8). Differential pressure sensors can measure volumetric flow rates by measuring the pressure difference between two points in a pipe. They offer high accuracy but are only suitable for low and medium flow rates due to their limited frequency range [34]. Thermal mass flow rate sensors use heat transfer effects to determine the mass flow rate of a gas or liquid without any moving parts. However, they require calibration with respect to temperature and pressure [35].\n",
      "\n",
      "#### Level Sensors\n",
      "\n",
      "For many applications (e.g., in process engineering), it is important to detect or measure levels of liquids or granular materials (Table 9). Ultrasonic sensors offer a wide measurement range, high accuracy, and good linearity due to their noncontact measurement principle. However, they are sensitive to temperature, humidity, and other environmental factors [36]. Capacitive level sensors provide excellent linearity and accuracy with low temperature dependence but require contact with the measured medium [37].\n",
      "\n",
      "#### Proximity Sensors\n",
      "\n",
      "For many applications (e.g., in robotics), it is important to detect objects or surfaces without touching them (Table 10). Ultrasonic proximity sensors use high-frequency sound waves to measure distances based on echo time and amplitude [38]. Capacitive proximity sensors measure capacitance changes between two electrodes, which can be used as a measure for the distance to an object or surface. However, they require contact with the measured medium due to their noncontact measurement principle [39].\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Differential pressure sensors & Pressure sensor that measures the pressure difference between two points in a pipe & 0 to +1 m/s (volumetric flow rate) & Typically 0.2–0.5\\% of reading & 0.1–0.3\\% \\\\ Thermal mass flow rate sensors & Sensing element that uses heat transfer effects to determine the mass flow rate of a gas or liquid & 0.01 to +50 kg/h (mass flow rate) & Typically 2–5\\% of reading & 1--10\\% \\\\ \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 8: Properties of Flow Rate Sensors#### Inclination Sensors\n",
      "\n",
      "For many applications, it is important to measure angles or inclinations (Table 11). Tilt sensors use a pendulum mechanism to detect changes in the angle of tilt. They offer high accuracy and low power consumption but are sensitive to vibrations [40]. Angular acceleration sensors use piezoelectric or capacitive elements to measure angular accelerations, which can be used as a measure for inclination. However, they require regular calibration due to their sensitivity to humidity, temperature, and other environmental factors [41].\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Ultrasonic proximity sensors & High-frequency sound waves to measure distances based on echo time and amplitude & 0 to +50 cm (distance) & Typically 1–2\\% of reading & 0.3--1.5\\% \\\\ Capacitive proximity sensors & Measures capacitance changes between two electrodes & 0 to +1 mm (distance) & Typically 1--3\\% of reading & 0.3--1.5\\% \\\\ \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 10: Properties of Proximity Sensors\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Ultrasonic level sensors & High-frequency sound waves to measure distances based on echo time and amplitude & 0 to +5 m (distance) & Typically 0.5--1\\% of reading & 0.2--1.5\\% \\\\ Capacitive level sensors & Measures capacitance changes between two electrodes & 0 to +10 cm (distance) & Typically 1--3\\% of reading & 0.5--3\\% \\\\ \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 9: Properties of Level Sensors#### Rotational Speed Sensors\n",
      "\n",
      "For many applications, it is important to measure rotational speeds or revolutions per minute (rpm) (Table 12). Optical rotary encoders use light barriers to detect the rotation of a shaft and determine its speed. They offer high accuracy and low power consumption but are sensitive to vibrations and require regular cleaning due to their susceptibility to dirt accumulation [42]. Inductive rotary encoders use an inductive principle to measure rotational speeds without any moving parts. However, they require a special winding pattern on the shaft and may cause electromagnetic interference [43].\n",
      "\n",
      "#### Temperature Sensors\n",
      "\n",
      "For many applications, it is important to measure temperatures (Table 13). Resistive temperature detectors (RTDs) use changes in electrical resistance to determine temperatures. They offer high accuracy and long-term stability but are relatively expensive compared to other temperature sensors [44]. Thermocouples use the Seebeck effect to generate a voltage proportional to the temperature difference between two junctions. They are simple, rugged, and cost-effective but have lower accuracy than RTDs [45].\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Optical rotary encoders & Light barriers to detect the rotation of a shaft and determine its speed & 0 to +12,000 rpm (rotational speed) & Typically 0.5–1\\% of reading & 0.1--0.3\\% \\\\ Inductive rotary encoders & Measures rotational speeds without any moving parts & 0 to +12,000 rpm (rotational speed) & Typically 1--3\\% of reading & 0.5--2\\% \\\\ \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 12: Properties of Rotational Speed Sensors#### Humidity Sensors\n",
      "\n",
      "For many applications, it is important to measure humidity levels (Table 14). Capacitive humidity sensors use changes in capacitance to determine the amount of moisture in the air. They offer high accuracy and long-term stability but are relatively expensive compared to other humidity sensors [46]. Resistive humidity sensors use changes in electrical resistance to determine the amount of moisture in the air. They are simple, rugged, and cost-effective but have lower accuracy than capacitive humidity sensors [47].\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Capacitive humidity sensors & Changes in capacitance to determine the amount of moisture in the air & 0 to +100\\% RH (humidity) & Typically 1--3\\% of reading & 1--5\\% \\\\ Resistive humidity sensors & Changes in electrical resistance to determine the amount of moisture in the air & 0 to +100\\% RH (humidity) & Typically 2--5\\% of reading & 2--10\\% \\\\ \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 14: Properties of Humidity Sensors\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Resistive temperature detectors (RTDs) & Changes in electrical resistance to determine temperatures & -200 to +850°C (temperature) & Typically 0.1--0.3\\% of reading & 0.1--0.5\\% \\\\ Thermocouples & Generate a voltage proportional to the temperature difference between two junctions & -200 to +1800°C (temperature) & Typically 1--5\\% of reading & 2--5\\% \\\\ \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 13: Properties of Temperature Sensors#### Pressure Sensors\n",
      "\n",
      "For many applications, it is important to measure pressures (Table 15). Strain gauge pressure sensors use changes in electrical resistance to determine the amount of force exerted on a diaphragm. They offer high accuracy and long-term stability but are relatively expensive compared to other pressure sensors [48]. Piezoelectric pressure sensors use the piezoelectric effect to generate a voltage proportional to the pressure applied. They are simple, rugged, and cost-effective but have lower accuracy than strain gauge pressure sensors [49].\n",
      "\n",
      "### Summary\n",
      "\n",
      "Sensors are essential components of automation systems that convert physical or chemical quantities into electrical signals for further processing and control. There are various types of sensors available, each with their unique characteristics and applications. The selection of the appropriate sensor depends on factors such as measurement range, accuracy, response time, environmental conditions, cost, and compatibility with other system components.\n",
      "\n",
      "This chapter presented an overview of the most common types of sensors used in automation systems, including position, force, temperature, pressure, flow rate, humidity, and rotational speed sensors. The working principles, characteristics, advantages, and disadvantages of each sensor type were discussed, along with their typical applications and selection criteria.\n",
      "\n",
      "The chapter also provided practical examples of how sensors are used in real-world automation systems to measure and control various physical quantities. These examples demonstrated the importance of accurate and reliable sensing in ensuring the performance, safety, and efficiency of automated processes.\n",
      "\n",
      "In conclusion, sensors play a critical role in automation systems by providing essential information about the state of the system and its environment. Understanding the different types of sensors available, their characteristics, advantages, and limitations is crucial for selecting and integrating appropriate sensing solutions into automation systems.\n",
      "\n",
      "\\begin{tabular}{l l l l l} \\hline Type & Transducer Element & Range & Linearity & Accuracy \\\\ \\hline Strain gauge pressure sensors & Changes in electrical resistance to determine the amount of force exerted on a diaphragm & 0 to +1,000 bar (pressure) & Typically 0.2--0.5\\% of reading & 0.1--0.3\\% \\\\ Piezoelectric pressure sensors & Generate a voltage proportional to the pressure applied & 0 to +1,000 bar (pressure) & Typically 1--5\\% of reading & 2--5\\% \\\\ \\hline \\end{tabular}\n",
      "\\end{table}\n",
      "Table 15: Properties of Pressure Sensors* [6] H. Ohm, The Galvanic Circuit Investigated Mathematically (Taylor and Francis, London, UK, 1891)\n",
      "\n",
      "_Peter C. Taylor and Kaveh Naderi_\n",
      "\n",
      "### Introduction\n",
      "\n",
      "Automation systems often need to handle materials that are fluid or have a liquid-like consistency, such as fluids, slurries, pastes, or powders. These materials can be moved, controlled, mixed, or processed using pumps, valves, and piping in various applications such as chemical processing, pharmaceuticals, food and beverage production, water treatment, and oil and gas exploration [1]. In these cases, the fluid handling system must ensure that the material flows at a desired rate and direction with minimal losses due to leaks or spills.\n",
      "\n",
      "In this chapter, we will discuss the principles and components of fluid handling systems used in automation applications. We will cover pumps, valves, piping, fittings, and seals, as well as flow measurement devices such as flow meters and pressure transducers. The chapter includes practical examples and best practices for designing, installing, maintaining, and troubleshooting fluid handling systems.\n",
      "\n",
      "### Pumps\n",
      "\n",
      "Pumps are mechanical devices that convert rotational or linear motion into hydraulic energy to move liquids or fluids from one location to another [2]. They can be classified based on their working principle, such as positive displacement pumps, centrifugal pumps, and kinetic pumps.\n",
      "\n",
      "Positive displacement pumps use a mechanical action to displace a fixed volume of fluid with each stroke or revolution. The most common types are reciprocating pumps, rotary vane pumps, and gear pumps. Reciprocating pumps have a piston that moves back and forth in a cylinder to suck and push the fluid. Rotary vane pumps use rotors with radial vanes to create chambers that fill and empty as they rotate, displacing the fluid. Gear pumps have two intermeshing gears that trap and pump the fluid between them as they rotate.\n",
      "\n",
      "Centrifugal pumps convert kinetic energy into potential energy by accelerating a liquid using a rotating impeller. The fluid enters the center of the impeller, gets centrifugally flung to the outer periphery, and exits through an outlet port. Centrifugal pumps can be further classified into single-stage or multi-stage designs depending on the number of impellers used.\n",
      "\n",
      "Kinetic pumps use the momentum of a fluid stream to create a pressure differential that moves the liquid. The most common types are jet pumps and ejectors, which use a high-velocity fluid jet to entrain and accelerate the fluid being pumped.\n",
      "\n",
      "Pumps can also be classified based on their application, such as general service, high-pressure, high-temperature, or hazardous fluids. The selection of the appropriate pump for a specific application depends on factors such as flow rate, pressure head, fluid viscosity, temperature, corrosiveness, toxicity, and safety requirements.\n",
      "\n",
      "The main parameters that describe the performance of a pump are its flow rate (Q), pressure head (H), power (P), efficiency (η), and NPSH (net positive suction head) [3]. The flow rate is the volume of fluid per unit time that the pump can deliver, typically expressed in liters per minute (L/min) or gallons per minute (GPM). The pressure head is the difference between the discharge pressure and the suction pressure, expressed in meters or feet of liquid column. The power is the energy required to operate the pump, usually measured in watts or horsepower. The efficiency is the ratio of the output power to the input power, expressed as a percentage. The NPSH is the minimum suction pressure required to prevent cavitation, which occurs when the pressure drops below the vapor pressure of the fluid, causing bubbles that can damage the pump and reduce its performance.\n",
      "\n",
      "### Valves\n",
      "\n",
      "Valves are mechanical devices that control the flow rate, direction, and pressure of fluids in a piping system [4]. They consist of a body, a stem or rod, a disc or plug, an actuator, and a packing or seal to prevent leaks. The valve body houses the fluid path, while the stem or rod connects the disc or plug to the actuator, which can be manual, pneumatic, hydraulic, or electric.\n",
      "\n",
      "Valves can be classified based on their function, such as shutoff, control, diversion, and safety valves. Shutoff valves are used to stop or start the flow of fluid by completely opening or closing the valve. Control valves regulate the flow rate, pressure, or direction of fluid by partially opening or closing the valve. Diversion valves distribute the fluid among multiple branches. Safety valves protect the system from overpressure or vacuum by releasing excess fluid when certain conditions are met.\n",
      "\n",
      "Valves can also be classified based on their construction and operation, such as globe, ball, butterfly, plug, diaphragm, and needle valves [5]. Globe valves have a linear motion that moves the disc against a seat to regulate the flow rate. Ball valves use a spherical disc with an opening in the middle to allow or block the flow of fluid. Butterfly valves have a flat disc mounted on a rod perpendicular to the flow direction, which rotates 90 degrees to open or close the valve. Plug valves have a cylindrical plug with an axial hole that aligns or misaligns with the inlet and outlet ports when rotated. Diaphragm valves use a flexible diaphragm that separates the fluid from the actuator, providing a leak-free seal. Needle valves have a long tapered needle that screws into the seat to regulate the flow rate accurately.\n",
      "\n",
      "The choice of valve for a specific application depends on factors such as flow rate, pressure drop, fluid properties, temperature, corrosiveness, toxicity, safety requirements, and cost. The design criteria for valves include their Cv value, which is the flow coefficient that relates the flow rate to the pressure drop across the valve, and their response time, accuracy, repeatability, and durability [6].\n",
      "\n",
      "### Piping\n",
      "\n",
      "Piping systems consist of pipes, fittings, couplings, flanges, gaskets, supports, and insulation that transport fluids from one location to another [7]. The design of piping systems must consider factors such as flow rate, pressure drop, fluid properties, temperature, corrosiveness, toxicity, safety requirements, and cost.\n",
      "\n",
      "Pipes are long hollow cylinders made of various materials such as steel, stainless steel, iron, copper, plastic, or composite. They can be classified based on their shape, such as round, square, rectangular, or oval. The selection of the pipe material depends on factors such as compatibility with the fluid, pressure rating, temperature range, corrosion resistance, mechanical strength, and cost.\n",
      "\n",
      "Fittings are devices that connect, branch, change direction, or terminate pipes. They can be classified based on their function, such as elbows, tees, couplings, unions, reducers, and caps. The selection of the fitting depends on factors such as size, material, pressure rating, temperature range, and cost.\n",
      "\n",
      "Couplings are devices that connect two pipes end-to-end. They can be classified based on their connection method, such as threaded, welded, flanged, or clamped. The selection of the coupling depends on factors such as size, material, pressure rating, temperature range, and ease of installation and removal.\n",
      "\n",
      "Flanges are devices that connect two pipes or components using bolts and gaskets. They can be classified based on their shape, such as flat face, raised face, ring joint, lap joint, and tongue-and-groove. The selection of the flange depends on factors such as size, material, pressure rating, temperature range, and compatibility with other components.\n",
      "\n",
      "Gaskets are devices that seal the interface between two surfaces, such as flanges or valve seats. They can be made of various materials such as rubber, graphite, PTFE (polytetrafluoroethylene), or metallic composites. The selection of the gasket depends on factors such as pressure rating, temperature range, fluid compatibility, and durability.\n",
      "\n",
      "Supports are devices that hold pipes in place and prevent them from sagging, bending, or vibrating excessively. They can be classified based on their type, such as hangers, trunnions, rollers, saddles, clamps, or anchors. The selection of the support depends on factors such as pipe size, weight, orientation, and operating conditions.\n",
      "\n",
      "Insulation is a material that covers pipes to prevent heat loss or gain, reduce condensation, protect personnel from burns or frostbite, and reduce noise. It can be made of various materials such as fiberglass, calcium silicate, polyurethane foam, or mineral wool. The selection of the insulation depends on factors such as temperature range, thermal conductivity, moisture resistance, durability, and cost.\n",
      "\n",
      "### Fittings\n",
      "\n",
      "Fittings are devices used to connect, redirect, or stop the flow of fluids in a piping system [8]. They can be classified based on their function, such as elbows, tees, couplings, unions, reducers, and caps. The selection of the fitting depends on factors such as size, material, pressure rating, temperature range, and cost.\n",
      "\n",
      "Elbows are fittings used to change the direction of the flow by 90 or 45 degrees. They can be classified based on their shape, such as long radius, short radius, compact, mitre, concentric, eccentric, and swivel. The choice of elbow depends on factors such as pipe size, fluid velocity, pressure drop, space availability, and cost.\n",
      "\n",
      "Tees are fittings used to split or combine the flow in three directions. They can be classified based on their connection method, such as welded, socket, threaded, flanged, or quick-connect. The choice of tee depends on factors such as pipe size, fluid properties, pressure drop, temperature range, and cost.\n",
      "\n",
      "Couplings are fittings used to connect two pipes end-to-end. They can be classified based on their connection method, such as threaded, welded, flanged, clamped, or compression. The choice of coupling depends on factors such as pipe size, material, pressure rating, temperature range, and ease of installation and removal.\n",
      "\n",
      "Unions are fittings used to connect two pipes using a male-female connection that can be disassembled without rotating the pipes. They can be classified based on their seal type, such as compression, O-ring, or gasket. The choice of union depends on factors such as pipe size, material, pressure rating, temperature range, and frequency of disassembly.\n",
      "\n",
      "Reducers are fittings used to change the diameter of a pipe up or down. They can be classified based on their shape, such as concentric, eccentric, tapered, or stepped. The choice of reducer depends on factors such as pipe size, fluid velocity, pressure drop, space availability, and cost.\n",
      "\n",
      "Caps are fittings used to close the end of a pipe or a branch of a tee. They can be classified based on their connection method, such as welded, threaded, flanged, or quick-connect. The choice of cap depends on factors such as pipe size, material, pressure rating, temperature range, and cost.\n",
      "\n",
      "### Seals\n",
      "\n",
      "Seals are devices used to prevent leakage between two surfaces that move relative to each other [9]. They can be classified based on their function, such as static, reciprocating, or rotary. The choice of seal depends on factors such as fluid properties, pressure rating, temperature range, speed, durability, and cost.\n",
      "\n",
      "Static seals are used when the two surfaces do not move relative to each other. They can be made of various materials such as rubber, plastic, graphite, PTFE (polytetrafluoroethylene), or metal. The most common types of static seals are O-rings, lip seals, and gaskets.\n",
      "\n",
      "O-rings are donut-shaped elastomeric seals that fit into a groove on one of the surfaces and compress when the two surfaces come together to form a leak-free seal. They can be made of various materials such as NBR (nitrile butadiene rubber), EPDM (ethylene propylene diene monomer), FKM (fluorocarbon elastomer), or silicone.\n",
      "\n",
      "Lip seals are elastomeric or metallic seals that have a flat or tapered face that contacts the other surface and forms a leak-free seal. They can be made of various materials such as PTFE, carbon graphite, or polyurethane.\n",
      "\n",
      "Gaskets are seals made of various materials such as rubber, paper, cardboard, cork, plastic, or metal. They are placed between the two surfaces and compressed when they come together to form a leak-free seal.\n",
      "\n",
      "Reciprocating seals are used when the two surfaces move relative to each other in a linear or oscillatory manner. They can be classified based on their construction, such as packing, piston ring, or cup seal. The choice of reciprocating seal depends on factors such as speed, pressure, temperature, durability, and lubrication.\n",
      "\n",
      "Packing is a generic term used to describe various types of seals that consist of braided or solid elastomeric rings impregnated with lubricant that are inserted into a stuffing box around the shaft or rod. They can be made of various materials such as PTFE, graphite, leather, rubber, or polyurethane.\n",
      "\n",
      "Piston rings are seals used in cylinder liners to prevent leakage between the piston and the liner. They can be made of various materials such as cast iron, steel, ceramic, or carbon graphite.\n",
      "\n",
      "Cup seals are seals that consist of a cup-shaped elastomeric or metallic element that fits around the shaft or rod and contacts the other surface when it rotates or oscillates. They can be made of various materials such as PTFE, rubber, polyurethane, or metal.\n",
      "\n",
      "Rotary seals are used when the two surfaces move relative to each other in a circular or angular manner. They can be classified based on their construction, such as labyrinth, lip, or face seal. The choice of rotary seal depends on factors such as speed, pressure, temperature, durability, and lubrication.\n",
      "\n",
      "Labyrinth seals are seals that consist of a series of concentric grooves or rings on one or both surfaces that form a tortuous path for the leakage to flow through. They can be made of various materials such as steel, aluminum, brass, or plastic.\n",
      "\n",
      "Lip seals are seals that consist of an elastomeric or metallic element with a flat or tapered face that contacts the other surface and forms a leak-free seal. They can be made of various materials such as PTFE, rubber, polyurethane, or metal.\n",
      "\n",
      "Face seals are seals that consist of two flat or curved surfaces that contact each other and form a leak-free seal by applying pressure and/or friction. They can be made of various materials such as carbon graphite, ceramic, metal, or engineering plastic.\n",
      "\n",
      "### Filters\n",
      "\n",
      "Filters are devices used to remove contaminants from fluids or gases [10]. They can be classified based on their function, such as liquid filter, air filter, or gas filter. The choice of filter depends on factors such as particle size, flow rate, pressure drop, temperature range, and cost.\n",
      "\n",
      "Liquid filters are used to remove solid particles or dissolved impurities from liquids. They can be classified based on their construction, such as depth filter, surface filter, or cartridge filter. The choice of liquid filter depends on factors such as particle size, flow rate, pressure drop, temperature range, and application.\n",
      "\n",
      "Depth filters are filters that consist of a porous material with a large surface area and a deep structure. They can remove small particles as well as dissolved impurities by trapping them inside the pores or adsorbing them on the surfaces. They can be made of various materials such as cellulose, glass fiber, polyester, or polypropylene.\n",
      "\n",
      "Surface filters are filters that consist of a thin layer of porous material with a small surface area and a shallow structure. They can remove larger particles by trapping them on the top of the layer. They can be made of various materials such as polyester, nylon, or PTFE (polytetrafluoroethylene).\n",
      "\n",
      "Cartridge filters are filters that consist of a replaceable element with a large surface area and a small volume. They can remove both solid particles and dissolved impurities by trapping them inside the pores or adsorbing them on the surfaces. They can be made of various materials such as polyester, glass fiber, PTFE (polytetrafluoroethylene), or activated carbon.\n",
      "\n",
      "Air filters are used to remove solid particles or gaseous impurities from air. They can be classified based on their construction, such as panel filter, bag filter, or cartridge filter. The choice of air filter depends on factors such as particle size, flow rate, pressure drop, temperature range, and application.\n",
      "\n",
      "Panel filters are filters that consist of a flat sheet of porous material with a large surface area and a small thickness. They can remove larger particles by trapping them on the top of the layer. They can be made of various materials such as polyester, glass fiber, or PTFE (polytetrafluoroethylene).\n",
      "\n",
      "Bag filters are filters that consist of a flexible container with a porous material inside. They can remove small particles as well as gaseous impurities by trapping them inside the pores or adsorbing them on the surfaces. They can be made of various materials such as polyester, glass fiber, or activated carbon.\n",
      "\n",
      "Cartridge filters are filters that consist of a replaceable element with a large surface area and a small volume. They can remove both solid particles and gaseous impurities by trapping them inside the pores or adsorbing them on the surfaces. They can be made of various materials such as polyester, glass fiber, PTFE (polytetrafluoroethylene), or activated carbon.\n",
      "\n",
      "Gas filters are used to remove solid particles or chemical impurities from gases. They can be classified based on their construction, such as coalescer filter, absorber, or scrubber. The choice of gas filter depends on factors such as particle size, flow rate, pressure drop, temperature range, and application.\n",
      "\n",
      "Coalescer filters are filters that consist of a porous material with a large surface area and a deep structure. They can remove small particles as well as liquid droplets by trapping them inside the pores or coalescing them on the surfaces. They can be made of various materials such as glass fiber, PTFE (polytetrafluoroethylene), or stainless steel.\n",
      "\n",
      "Absorbers are filters that consist of a porous material with a large surface area and a deep structure. They can remove gaseous impurities by trapping them inside the pores or adsorbing them on the surfaces. They can be made of various materials such as activated carbon, silica gel, or alumina.\n",
      "\n",
      "Scrubbers are filters that consist of a liquid spray nozzle with a large surface area and a shallow structure. They can remove gaseous impurities by dissolving them in the liquid or reacting with them chemically. They can be made of various materials such as stainless steel, glass fiber, or plastic.\n",
      "Metrics of Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas: 100%|██████████████████████████████████████████████████████████| 3/3 [2:41:17<00:00, 3225.84s/it]\u001b[A\n",
      "Progreso_de_textos:  60%|██████████████████████████████████▊                       | 3/5 [5:29:12<4:04:33, 7336.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of this text are about the evaluation of models using four key metrics: accuracy, precision, recall, and the F1 score. These metrics are based on the True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN) values derived from the model's predictions.\n",
      "\n",
      "* **Accuracy** is the ratio of correct predictions to the total number of instances, providing an overall measure of how often the model is correct in its predictions.\n",
      "* **Precision** is defined as the proportion of true positive predictions out of all positive predictions, measuring the model's ability to correctly identify positive instances.\n",
      "* **Recall**, also known as sensitivity, measures the proportion of actual positive instances that were correctly identified, providing a measure of the model's ability to correctly identify positive instances.\n",
      "* The **F1 score** is the harmonic mean of precision and recall, giving equal weight to both metrics and ranges from 0 to 1. It is useful when dealing with imbalanced datasets as it takes both false positives and false negatives into account.\n",
      "\n",
      "These metrics provide a comprehensive evaluation of the model's performance by considering both precision and recall, and the F1 score offers a balance between these two metrics, making it a better choice than accuracy when dealing with imbalanced datasets.\n",
      "\n",
      "Additionally, the text includes a reference to a figure (Figure 2) showing a flow diagram of DistilBERT, but there are no principal ideas provided in the text related to this figure.\n",
      "Procesando texto No. 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:   0%|                                                                      | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Substitution-based in-context example optimization (SICO)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  25%|███████████████▌                                              | 1/4 [01:21<04:03, 81.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of this text are:\n",
      "\n",
      "1. SICO is a system for generating human-like text.\n",
      "2. The process of creating a prompt for SICO involves extracting language features from human-written text using LLM, initializing and optimizing in-context examples, and combining these elements with a task instruction to create the final prompt.\n",
      "3. The optimization of the prompt is evaluated by an unspecified method.\n",
      "4. The text also provides more detail on each step of the SICO process, although this is not a principal idea.\n",
      "\n",
      "The text does not contain any overarching arguments or themes, and the principal ideas listed above are simply a summary of the steps involved in creating a prompt for the SICO system.\n",
      "Prompt evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  50%|██████████████████████████████▌                              | 2/4 [18:06<20:49, 624.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of the text are:\n",
      "\n",
      "1. The utility of a prompt in a natural language processing task is assessed by collecting a set of task inputs and concatenating each input with the prompt, which is then fed into a large language model (LLM).\n",
      "2. The output text from the LLM is classified by a proxy detector to predict the probability of it being AI-generated, denoted as \\(P_{AI}\\).\n",
      "3. The utility score of the prompt is defined as one minus the average predicted probability across all task inputs in the evaluation set.\n",
      "4. A higher utility score indicates that the prompt is better at generating non-AI-like text.\n",
      "5. The text also mentions SICO, a system for generating prompts for the question answering task, which uses the probability of AI-generation to indicate the likelihood of a given text being AI-generated.\n",
      "6. Once a SICO prompt is constructed, it serves as a template for users to insert various task inputs.\n",
      "Prompt Construction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  75%|███████████████████████████████████████████▌              | 3/4 [1:02:41<26:00, 1560.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The text describes a method called SICO (Substitution-based In-Context Optimization) for optimizing language generation by a large language model (LLM). The main ideas are:\n",
      "\n",
      "1. Data collection: Creating a dataset \\(D\\) of task inputs and corresponding outputs generated by the LLM and humans, respectively. This dataset is used for prompt construction and is independent of the evaluation set \\(X_{eval}\\).\n",
      "2. Feature extraction: Using the LLM to extract distinct linguistic features of human-written text from pairs of AI-generated and human-written outputs from \\(D\\).\n",
      "3. In-context example optimization: Initializing in-context examples by paraphrasing AI-generated outputs using a text feature as input. The in-context output is then optimized iteratively to be less AI-like, maintaining semantic similarity through substitution and rephrasing techniques.\n",
      "4. Substitution types: Word-level substitution utilizing synonym sets constructed from WordNet, ensuring part-of-speech tags are maintained. Sentence-level substitution uses a paraphrasing instruction combined with the extracted feature to generate semantically similar sentences.\n",
      "5. Algorithm: SICO iteratively optimizes in-context outputs using greedy substitution and compares new prompts based on utility scores. The final prompt is returned after \\(N\\) iterations.\n",
      "SICO for Paraphrasing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas: 100%|██████████████████████████████████████████████████████████| 4/4 [1:10:28<00:00, 1057.15s/it]\u001b[A\n",
      "Progreso_de_textos:  80%|██████████████████████████████████████████████▍           | 4/5 [6:39:41<1:41:49, 6109.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of this text are:\n",
      "\n",
      "1. There are two approaches for generating task output using SICO: SICO-Gen and SICO-Para.\n",
      "2. SICO-Gen directly generates the task output to evade detectors, while SICO-Para uses a two-step process of first producing an intermediate task output that is then paraphrased to successfully evade detectors.\n",
      "3. To switch from SICO-Gen to SICO-Para, there are two required adjustments: (1) the task input x is set to the AI-generated output text in D and X\\_eval, and (2) the task instruction p\\_{task} is modified to a paraphrasing instruction.\n",
      "Procesando texto No. 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:   0%|                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 RADAR: Methodology and Algorithms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  20%|███████████▌                                              | 1/5 [20:56<1:23:47, 1256.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of the text are:\n",
      "\n",
      "1. Introduction of the RADAR framework, which consists of three neural-network-based language models: the target LM (θ), the detector (Dphi), and the paraphraser (Gσ).\n",
      "2. The training process involves four steps:\n",
      "a. Data preparation by creating a corpus of AI-text (M) using document completion from human-text corpus (H) with the target LM (Tθ).\n",
      "b. Updating the paraphraser (Gphi) using Proximal Policy Optimization (PPO) and the reward from the detector (Dtheta).\n",
      "c. Updating the detector (Dtheta) using logistic loss function and human-text samples (Xh), original AI-text samples (Xm), and paraphrased AI-text samples (Xp).\n",
      "d. Validating and evaluating RADAR's performance using a test set of WebText during training and calculating the detection AUROC with Tθ for the evaluation dataset.\n",
      "3. Steps 2 to 3 are repeated until there is no improvement in the AUROC evaluated on the validation dataset, aiming to make the detector robust in detecting both original and paraphrased AI-text.\n",
      "Training Paraphraser via Clipped PPO with Entropy Penalty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  40%|███████████████████████▏                                  | 2/5 [52:29<1:21:31, 1630.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of the text are:\n",
      "\n",
      "1. RADAR is a system with a paraphraser model \\(\\mathcal{G}_sigma}\\) that generates paraphrased text \\(x_{p}\\) from machine-generated input text \\(x_{m}\\).\n",
      "2. The paraphrasing process is viewed as a decision-making procedure, where the current state is the input text and the output text is the action taken.\n",
      "3. Reinforcement learning with Proximal Policy Optimization (PPO) is used to optimize \\(\\mathcal{G}_sigma}\\), using reward feedback from the detector model \\(\\mathcal{D}_phi}\\). The detector predicts the likelihood of \\(x_{p}\\) being human-written text.\n",
      "m E}\\)).and diversity (\\(L_{PPO with Entropy Penalty (cppo-ep) to improve optimization, balancing between advantage (\\(L_{\n",
      "m E}\\)), which encourages exploration of diverse generation policies.ntropy term (\\(L_{tive (\\(L_{\n",
      "6. The expectation (\\(\\mathbb{E}\\)) in the cppo-ep loss function calculates the expected value over state-action pairs sampled from a policy.\n",
      "7. The importance sampling ratio \\(r(sigma}, x_{m}, x_{p})\\) represents the likelihood of a new policy \\(\\mathcal{G}_sigma}\\) generating a given state-action pair compared to an old policy \\(\\mathcal{G}_sigma'}\\).\n",
      "8. The advantage item \\(A(x_{p},phi})\\) is obtained by normalizing the reward \\(R(x_{p},phi})\\) across the entire PPO sample buffer \\(\\mathcal{B}\\), promoting paraphrases that resemble human text.\n",
      "9. The entropy term \\(S(sigma})\\) encourages exploration of diverse generation policies, preventing overfitting or degenerate solutions in the paraphrasing process.\n",
      "Training Detector via Reweighted Logistic Loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  60%|██████████████████████████████████▊                       | 3/5 [1:10:04<45:35, 1367.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of this text are:\n",
      "\n",
      "1. In a typical GAN (Generative Adversarial Network) training process, the discriminator receives an equal number of positive and negative samples in each step, maintaining an in-batch sample balance.\n",
      "2. However, RADAR, a specific system, has an imbalance problem because it pairs each human-text sample with two AI-text samples: one original and one paraphrased.\n",
      "3. To address this imbalance, the authors use a reweighted logistic loss function to optimize the detector in RADAR. This loss function consists of three parts: one for human-text, one for original AI-text, and one for paraphrased AI-text.\n",
      "4. The coefficient \\(\\lambda\\) is introduced to adjust the proportion of AI-text components in the overall loss function, helping alleviate the effects of sample imbalance.\n",
      "RADAR Algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas:  80%|██████████████████████████████████████████████▍           | 4/5 [1:27:21<20:37, 1237.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The principal ideas of the text are:\n",
      "\n",
      "1. RADAR is a training procedure for a paraphraser and detector.\n",
      "2. The training process includes data initialization, model initialization, and model training steps.\n",
      "3. Data initialization involves collecting human-written text, building a human-text corpus, selecting a target language model, building an AI-text corpus, creating a replay buffer, and building a validation dataset.\n",
      "4. Model initialization sets the detector and paraphraser as pretrained language models.\n",
      "5. During model training, the paraphraser generates a paraphrase of a sample from the human-text corpus and the AI-text corpus.\n",
      "6. A reward is collected based on the generated paraphrase, and an advantage function is computed using the reward.\n",
      "7. The replay buffer is filled with the sampled data and the corresponding advantage function value.\n",
      "8. The paraphraser's parameters are updated using the Proximal Policy Optimization (PPO) algorithm.\n",
      "9. In the evaluation phase, the detector predicts the likelihood of AI-text for any input instance.\n",
      "initialize the old policy \\(\\sigma^{\\prime}\\) as the current policy \\(\\sigma\\)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Secciones procesadas: 100%|██████████████████████████████████████████████████████████| 5/5 [1:43:04<00:00, 1236.81s/it]\u001b[A\n",
      "Progreso_de_textos: 100%|████████████████████████████████████████████████████████████| 5/5 [8:22:45<00:00, 6033.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The given text appears to be a part of a pseudocode or algorithm, specifically Algorithm 1, which is named \"RADAR: Robust AI-Text Detection via Adversarial Learning.\" Here are the principal ideas presented in this text:\n",
      "\n",
      "1. **Data processing:** The algorithm iterates through a dataset `B` consisting of tuples containing input data `(xh, xm, xp)` and corresponding labels `A(xp, φ)`.\n",
      "2. **Log probability computation:** For each tuple in the dataset `B`, the algorithm computes the log probability of the positive sample `xp` given the masked text `xm` using two generative models (`PGσ` and `PG'σ`).\n",
      "3. **Model updates based on computed probabilities:** The algorithm then updates one of the generative models, `PGσ`, based on the log probability computations performed in step 2. This update is done according to Eq. 2 mentioned in the algorithm.\n",
      "4. **Model parameter optimization:** After updating the model, the algorithm optimizes the parameters of a detector model, `Dφ`, using Eq. 3. This optimization step is also carried out for each tuple in the dataset.\n",
      "5. **Validation and best-performing models selection:** Once all tuples have been processed, the algorithm evaluates the performance of the detector model `Dφ` on a validation dataset `V`. It selects the best-performing detector model (highest AUROC value) as `Dphi_best` along with its corresponding paraphraser model (`Gsigma_best`).\n",
      "6. **Returning the optimized models:** Finally, the algorithm returns the best-performing detector and paraphraser models.\n",
      "\n",
      "Overall, this text describes an iterative process of data processing, probability computation, model updates, parameter optimization, validation, and selection for a pair of generative and detector models in the context of text detection via adversarial learning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def modelo(model,text):\n",
    "    query = \"Give the principal ideas about this text, if there are not principal ideas only give that 'no principal ideas detect': \" + \"'\" + text + \"'\" \n",
    "    response = ollama.chat(model=model, messages=[\n",
    "      {\n",
    "        'role': 'user',\n",
    "        'content': query,\n",
    "        'temperature': 0.75,\n",
    "        'stream': False\n",
    "      },\n",
    "    ])\n",
    "    print(response['message']['content'])\n",
    "    respuesta = response['message']['content']\n",
    "    return respuesta\n",
    "\n",
    "respuesta_llama_3 = []\n",
    "\n",
    "def texto_proceso(texto_final):\n",
    "    respuesta = {}\n",
    "    for textos in tqdm(texto_final,desc=\"Secciones procesadas\"):\n",
    "        print(textos)\n",
    "        contenido = texto_final[textos]\n",
    "        #print(f\"Contenido: {contenido}\")\n",
    "        respuesta[textos] = modelo('mixtral',contenido)\n",
    "    return respuesta\n",
    "\n",
    "respuesta = []\n",
    "j = 0\n",
    "for text_fuera in tqdm(textos_finales,desc=\"Progreso_de_textos: \"):\n",
    "    \n",
    "    print(f\"Procesando texto No. {j}\")\n",
    "    respuesta.append(texto_proceso(text_fuera))\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b45d7bb-3122-4045-a17e-200900a7982f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(respuesta[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "469691e9-2d13-48de-8886-094600982938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['3 Our Method', 'Paraphrasing Model', 'LLM Integration', 'Evaluation Process', 'Cosine Similarity', 'Linear Discriminant Analysis'])\n"
     ]
    }
   ],
   "source": [
    "print((respuesta[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1061dc14-3eae-4726-87ce-d8982ca181d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "nombre = \"Texto\"\n",
    "k = 0\n",
    "diccionario = {}\n",
    "for i in respuesta:\n",
    "    print(type(i))\n",
    "    nombre_completo = nombre + \"_\" + str(k)\n",
    "    diccionario[nombre_completo] = i\n",
    "    k= k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63302009-5401-4b35-bef4-0a4efed2a604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Texto_0', 'Texto_1', 'Texto_2', 'Texto_3', 'Texto_4'])\n"
     ]
    }
   ],
   "source": [
    "print(diccionario.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72b5d8d7-e952-494d-8429-9882457d345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_archivo_json = \"F:/nuevo_conocimiento/Alex Project/New_part_project/diccionario_metodologia_mixtral.json\"\n",
    "with open(ruta_archivo_json, 'w', encoding='utf-8') as archivo_json:\n",
    "    json.dump(diccionario, archivo_json, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a63a15-79b5-4233-a36b-c25bb917e212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_1",
   "language": "python",
   "name": "gpu_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
